{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e1cffa2",
   "metadata": {},
   "source": [
    "# Circadian Dysregulation & Behavioral Symptom Burden\n",
    "\n",
    "**PeriNeuroImmuneMap Analysis Pipeline**\n",
    "\n",
    "---\n",
    "\n",
    "**Correspondence:** Wei Qin (<wqin@sjtu.edu.cn>)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1d5549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path('.')\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "OUTPUT_DIR = BASE_DIR / 'outputs'\n",
    "FIGURE_DIR = OUTPUT_DIR / 'figures'\n",
    "TABLE_DIR  = OUTPUT_DIR / 'tables'\n",
    "\n",
    "for d in [DATA_DIR, OUTPUT_DIR, FIGURE_DIR, TABLE_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('✓ Paths configured')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5e1a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, base64, json, subprocess, tempfile, shutil\n",
    "from pathlib import Path\n",
    "from getpass import getpass\n",
    "import nbformat\n",
    "\n",
    "# -------------------------\n",
    "# CONFIG (edit if needed)\n",
    "# -------------------------\n",
    "REPO_OWNER = \"Sjtu-Fuxilab\"\n",
    "REPO_NAME  = \"PeriNeuroImmuneMap\"\n",
    "\n",
    "# ✅ Your correct notebook path:\n",
    "NOTEBOOK_LOCAL_PATH = r\"D:\\个人文件夹\\Sanwal\\Neuro\\nc.ipynb\"\n",
    "\n",
    "# Where to place it inside the repo:\n",
    "DEST_PATH_IN_REPO = \"notebooks/nc.ipynb\"   # change to \"nc.ipynb\" if you want it at repo root\n",
    "\n",
    "# API limit safety (GitHub contents API is ~1MB; keep margin)\n",
    "MAX_API_BYTES = 900_000\n",
    "\n",
    "# -------------------------\n",
    "# Helpers\n",
    "# -------------------------\n",
    "def ensure_requests():\n",
    "    try:\n",
    "        import requests\n",
    "        return requests\n",
    "    except Exception:\n",
    "        print(\"Installing requests...\")\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"requests\"])\n",
    "        import requests\n",
    "        return requests\n",
    "\n",
    "def gh_headers(token):\n",
    "    return {\n",
    "        \"Authorization\": f\"token {token}\",\n",
    "        \"Accept\": \"application/vnd.github+json\",\n",
    "    }\n",
    "\n",
    "def gh_repo_info(requests, token):\n",
    "    url = f\"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}\"\n",
    "    r = requests.get(url, headers=gh_headers(token))\n",
    "    if r.status_code != 200:\n",
    "        raise RuntimeError(f\"Repo not accessible. HTTP {r.status_code}: {r.text}\")\n",
    "    return r.json()\n",
    "\n",
    "def gh_get_sha_if_exists(requests, token, repo_path):\n",
    "    url = f\"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/{repo_path}\"\n",
    "    r = requests.get(url, headers=gh_headers(token))\n",
    "    if r.status_code == 200:\n",
    "        return r.json().get(\"sha\")\n",
    "    if r.status_code == 404:\n",
    "        return None\n",
    "    raise RuntimeError(f\"Failed checking existing file. HTTP {r.status_code}: {r.text}\")\n",
    "\n",
    "def upload_via_contents_api(requests, token, local_path, repo_path, commit_message):\n",
    "    local_path = Path(local_path)\n",
    "    data_bytes = local_path.read_bytes()\n",
    "    content_b64 = base64.b64encode(data_bytes).decode(\"utf-8\")\n",
    "\n",
    "    sha = gh_get_sha_if_exists(requests, token, repo_path)\n",
    "\n",
    "    url = f\"https://api.github.com/repos/{REPO_OWNER}/{REPO_NAME}/contents/{repo_path}\"\n",
    "    payload = {\"message\": commit_message, \"content\": content_b64}\n",
    "    if sha:\n",
    "        payload[\"sha\"] = sha\n",
    "\n",
    "    r = requests.put(url, headers=gh_headers(token), json=payload)\n",
    "    if r.status_code in (200, 201):\n",
    "        return True, r.json()\n",
    "    return False, r.text\n",
    "\n",
    "def run(cmd, cwd=None):\n",
    "    p = subprocess.run(cmd, cwd=cwd, text=True, capture_output=True)\n",
    "    if p.returncode != 0:\n",
    "        raise RuntimeError(f\"Command failed:\\n  {' '.join(cmd)}\\n\\nSTDOUT:\\n{p.stdout}\\n\\nSTDERR:\\n{p.stderr}\")\n",
    "    return p.stdout.strip()\n",
    "\n",
    "def upload_via_git(token, default_branch, local_path, repo_path):\n",
    "    # Requires git installed\n",
    "    run([\"git\", \"--version\"])\n",
    "\n",
    "    tmpdir = Path(tempfile.mkdtemp(prefix=\"gh_upload_\"))\n",
    "    try:\n",
    "        # Clone using token (stored temporarily); then sanitize remote url after push\n",
    "        clone_url_with_token = f\"https://{token}@github.com/{REPO_OWNER}/{REPO_NAME}.git\"\n",
    "        print(f\"Cloning into temp dir: {tmpdir}\")\n",
    "        run([\"git\", \"clone\", \"--depth\", \"1\", \"--branch\", default_branch, clone_url_with_token, str(tmpdir)])\n",
    "\n",
    "        # Copy notebook into repo path\n",
    "        target = tmpdir / repo_path\n",
    "        target.parent.mkdir(parents=True, exist_ok=True)\n",
    "        shutil.copy2(str(local_path), str(target))\n",
    "\n",
    "        # Commit & push\n",
    "        run([\"git\", \"add\", repo_path], cwd=tmpdir)\n",
    "        # If no changes, git commit will fail; detect with status porcelain\n",
    "        status = run([\"git\", \"status\", \"--porcelain\"], cwd=tmpdir)\n",
    "        if not status.strip():\n",
    "            print(\"No changes detected (remote already has identical file). Nothing to push.\")\n",
    "        else:\n",
    "            # Set a local identity (won't affect your global git)\n",
    "            run([\"git\", \"config\", \"user.email\", \"actions@users.noreply.github.com\"], cwd=tmpdir)\n",
    "            run([\"git\", \"config\", \"user.name\", \"Notebook Uploader\"], cwd=tmpdir)\n",
    "            run([\"git\", \"commit\", \"-m\", f\"Update {repo_path}\"], cwd=tmpdir)\n",
    "            run([\"git\", \"push\", \"origin\", default_branch], cwd=tmpdir)\n",
    "            print(\"Pushed changes via git.\")\n",
    "\n",
    "        # Sanitize remote URL to remove token from .git/config in temp clone\n",
    "        run([\"git\", \"remote\", \"set-url\", \"origin\", f\"https://github.com/{REPO_OWNER}/{REPO_NAME}.git\"], cwd=tmpdir)\n",
    "        return True\n",
    "    finally:\n",
    "        shutil.rmtree(tmpdir, ignore_errors=True)\n",
    "\n",
    "# -------------------------\n",
    "# Main\n",
    "# -------------------------\n",
    "print(\"=\" * 80)\n",
    "print(\"Upload complete notebook to GitHub (without outputs)\")\n",
    "print(f\"Local notebook: {NOTEBOOK_LOCAL_PATH}\")\n",
    "print(f\"Repo target:   https://github.com/{REPO_OWNER}/{REPO_NAME}  ->  {DEST_PATH_IN_REPO}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Remove outputs from the notebook\n",
    "def clear_notebook_outputs(nb_path):\n",
    "    \"\"\"Remove all outputs from the notebook.\"\"\"\n",
    "    with open(nb_path, 'r', encoding=\"utf-8\") as f:\n",
    "        nb = nbformat.read(f, as_version=4)\n",
    "    \n",
    "    for cell in nb.cells:\n",
    "        cell['outputs'] = []\n",
    "        cell['execution_count'] = None\n",
    "    \n",
    "    with open(nb_path, 'w', encoding=\"utf-8\") as f:\n",
    "        nbformat.write(nb, f)\n",
    "    print(\"✅ Outputs removed from notebook.\")\n",
    "\n",
    "clear_notebook_outputs(NOTEBOOK_LOCAL_PATH)\n",
    "\n",
    "nb_path = Path(NOTEBOOK_LOCAL_PATH)\n",
    "if not nb_path.exists():\n",
    "    raise FileNotFoundError(f\"Notebook not found:\\n  {NOTEBOOK_LOCAL_PATH}\")\n",
    "\n",
    "token = getpass(\"GitHub Personal Access Token (PAT): \").strip()\n",
    "if not token:\n",
    "    raise SystemExit(\"No token provided. Exiting.\")\n",
    "\n",
    "requests = ensure_requests()\n",
    "repo = gh_repo_info(requests, token)\n",
    "default_branch = repo.get(\"default_branch\", \"main\")\n",
    "\n",
    "size_bytes = nb_path.stat().st_size\n",
    "print(f\"\\nNotebook size: {size_bytes:,} bytes\")\n",
    "\n",
    "# Try Contents API first if size is safe\n",
    "if size_bytes <= MAX_API_BYTES:\n",
    "    print(\"\\nTrying GitHub Contents API upload...\")\n",
    "    ok, info = upload_via_contents_api(\n",
    "        requests,\n",
    "        token,\n",
    "        nb_path,\n",
    "        DEST_PATH_IN_REPO,\n",
    "        commit_message=f\"Upload notebook {DEST_PATH_IN_REPO}\"\n",
    "    )\n",
    "    if ok:\n",
    "        print(\"✅ Uploaded via Contents API.\")\n",
    "        print(f\"Done: https://github.com/{REPO_OWNER}/{REPO_NAME}/blob/{default_branch}/{DEST_PATH_IN_REPO}\")\n",
    "    else:\n",
    "        print(\"⚠️ Contents API upload failed; falling back to git method...\")\n",
    "        print(info if isinstance(info, str) else json.dumps(info, indent=2))\n",
    "        print(\"\\nTrying git clone/commit/push...\")\n",
    "        ok2 = upload_via_git(token, default_branch, nb_path, DEST_PATH_IN_REPO)\n",
    "        if ok2:\n",
    "            print(\"✅ Uploaded via git.\")\n",
    "            print(f\"Done: https://github.com/{REPO_OWNER}/{REPO_NAME}/blob/{default_branch}/{DEST_PATH_IN_REPO}\")\n",
    "else:\n",
    "    # Too large: go straight to git method\n",
    "    print(\"\\nNotebook is large; using git clone/commit/push (avoids Contents API size limits)...\")\n",
    "    ok2 = upload_via_git(token, default_branch, nb_path, DEST_PATH_IN_REPO)\n",
    "    if ok2:\n",
    "        print(\"✅ Uploaded via git.\")\n",
    "        print(f\"Done: https://github.com/{REPO_OWNER}/{REPO_NAME}/blob/{default_branch}/{DEST_PATH_IN_REPO}\")\n",
    "\n",
    "print(\"\\nAll done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.5.1 (histopathology)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}