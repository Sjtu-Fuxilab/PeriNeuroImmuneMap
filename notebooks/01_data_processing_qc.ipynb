{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f4e6761",
   "metadata": {},
   "source": [
    "# Data Processing, Quality Control & Spatial Feature Engineering\n",
    "\n",
    "**PeriNeuroImmuneMap Analysis Pipeline**\n",
    "\n",
    "---\n",
    "\n",
    "**Correspondence:** Wei Qin (<wqin@sjtu.edu.cn>)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557fb402",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path('.')\n",
    "DATA_DIR = BASE_DIR / 'data'\n",
    "OUTPUT_DIR = BASE_DIR / 'outputs'\n",
    "FIGURE_DIR = OUTPUT_DIR / 'figures'\n",
    "TABLE_DIR  = OUTPUT_DIR / 'tables'\n",
    "\n",
    "for d in [DATA_DIR, OUTPUT_DIR, FIGURE_DIR, TABLE_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print('✓ Paths configured')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa4c0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook 1: Data Processing, QC & Spatial Feature Engineering\n",
    "\n",
    "import os, sys, platform, time, json, gzip, pickle, warnings, hashlib, gc\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "from scipy.io import mmread\n",
    "from scipy.stats import median_abs_deviation, spearmanr\n",
    "from scipy.spatial import Delaunay\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import patheffects as pe\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import psutil\n",
    "\n",
    "sc.settings.verbosity = 2\n",
    "sc.settings.n_jobs = -1\n",
    "\n",
    "RUN_TS = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "import random\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "SAVE_DPI = 1200\n",
    "RUN_BENCHMARK = True\n",
    "\n",
    "BASE_DIR = Path(r\"D:\\个人文件夹\\Sanwal\\Neuro\")\n",
    "RAW_DATA_DIR = BASE_DIR / \"Raw data\"\n",
    "\n",
    "MANUSCRIPT_DIR = BASE_DIR / \"Manuscript Data\"\n",
    "FIGURES_DIR = MANUSCRIPT_DIR / \"Figures\"\n",
    "TABLES_DIR = MANUSCRIPT_DIR / \"Tables\"\n",
    "PROCESSED_DIR = BASE_DIR / \"processed\" / \"notebook1\"\n",
    "\n",
    "for d in [FIGURES_DIR, TABLES_DIR, PROCESSED_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "GSE_DIR = RAW_DATA_DIR / \"GSE289745\"\n",
    "if not GSE_DIR.exists():\n",
    "    raise FileNotFoundError(f\"GSE289745 folder not found: {GSE_DIR}\")\n",
    "\n",
    "LOG_PATH = PROCESSED_DIR / \"run_log.txt\"\n",
    "REQ_PATH = PROCESSED_DIR / \"requirements.txt\"\n",
    "CHK_PATH = PROCESSED_DIR / \"checksums.md5\"\n",
    "CHECKLIST_PATH = PROCESSED_DIR / \"reproducibility_checklist.txt\"\n",
    "\n",
    "\n",
    "def set_n_style():\n",
    "    mpl.rcParams.update({\n",
    "        \"font.family\": \"sans-serif\",\n",
    "        \"font.sans-serif\": [\"Arial\", \"Helvetica\", \"DejaVu Sans\"],\n",
    "        \"font.size\": 7,\n",
    "        \"axes.titlesize\": 7,\n",
    "        \"axes.labelsize\": 7,\n",
    "        \"xtick.labelsize\": 6,\n",
    "        \"ytick.labelsize\": 6,\n",
    "        \"legend.fontsize\": 6,\n",
    "        \"axes.linewidth\": 0.6,\n",
    "        \"lines.linewidth\": 0.8,\n",
    "        \"xtick.major.width\": 0.6,\n",
    "        \"ytick.major.width\": 0.6,\n",
    "        \"xtick.direction\": \"in\",\n",
    "        \"ytick.direction\": \"in\",\n",
    "        \"savefig.dpi\": SAVE_DPI,\n",
    "        \"pdf.fonttype\": 42,\n",
    "        \"ps.fonttype\": 42,\n",
    "    })\n",
    "\n",
    "\n",
    "set_n_style()\n",
    "\n",
    "\n",
    "def log(msg: str):\n",
    "    print(msg)\n",
    "    with open(LOG_PATH, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(msg.rstrip() + \"\\n\")\n",
    "\n",
    "\n",
    "with open(LOG_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"PeriNeuroImmuneMap Notebook 1 log\\n\")\n",
    "    f.write(f\"Start: {RUN_TS}\\n\")\n",
    "\n",
    "log(f\"Python: {sys.version}\")\n",
    "log(f\"Platform: {platform.platform()}\")\n",
    "log(f\"Seed: {RANDOM_SEED}\")\n",
    "log(f\"CPU logical: {psutil.cpu_count(True)} | CPU physical: {psutil.cpu_count(False)}\")\n",
    "log(f\"RAM total GB: {psutil.virtual_memory().total/(1024**3):.2f}\")\n",
    "log(f\"scanpy: {sc.__version__} | anndata: {ad.__version__}\")\n",
    "\n",
    "\n",
    "REQ_PATH.write_text(\n",
    "    \"\\n\".join([\n",
    "        \"# PeriNeuroImmuneMap Notebook 1 requirements\",\n",
    "        f\"# Generated: {RUN_TS}\",\n",
    "        f\"python=={sys.version.split()[0]}\",\n",
    "        \"scikit-misc>=0.3.1\",\n",
    "        \"scipy>=1.9.0\",\n",
    "        \"matplotlib>=3.6.0\",\n",
    "        \"scikit-learn>=1.1.0\",\n",
    "        \"openpyxl>=3.0.0\",\n",
    "        \"psutil>=5.9.0\",\n",
    "    ]),\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "log(f\"Saved requirements: {REQ_PATH}\")\n",
    "\n",
    "\n",
    "def find_existing(base: Path, candidates):\n",
    "    for name in candidates:\n",
    "        p = base / name\n",
    "        if p.exists():\n",
    "            return p\n",
    "    return None\n",
    "\n",
    "\n",
    "def open_maybe_gz(path: Path, mode=\"rt\"):\n",
    "    if path.suffix == \".gz\":\n",
    "        return gzip.open(path, mode)\n",
    "    return open(path, mode)\n",
    "\n",
    "\n",
    "def md5_file(path: Path, chunk_size=1024 * 1024):\n",
    "    h = hashlib.md5()\n",
    "    with open(path, \"rb\") as f:\n",
    "        while True:\n",
    "            b = f.read(chunk_size)\n",
    "            if not b:\n",
    "                break\n",
    "            h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "\n",
    "def safe_sparse_sum(x, axis=None):\n",
    "    if sp.issparse(x):\n",
    "        return np.asarray(x.sum(axis=axis)).ravel()\n",
    "    return np.asarray(np.sum(x, axis=axis)).ravel()\n",
    "\n",
    "\n",
    "def load_visium_components(sample_id: str, base_dir: Path) -> ad.AnnData:\n",
    "    mtx = find_existing(base_dir, [f\"{sample_id}_matrix.mtx.gz\", f\"{sample_id}_matrix.mtx\"])\n",
    "    feat = find_existing(base_dir, [f\"{sample_id}_features.tsv.gz\", f\"{sample_id}_features.tsv\"])\n",
    "    bc  = find_existing(base_dir, [f\"{sample_id}_barcodes.tsv.gz\", f\"{sample_id}_barcodes.tsv\"])\n",
    "    pos = find_existing(base_dir, [f\"{sample_id}_tissue_positions_list.csv.gz\", f\"{sample_id}_tissue_positions_list.csv\"])\n",
    "    sf  = find_existing(base_dir, [f\"{sample_id}_scalefactors_json.json.gz\", f\"{sample_id}_scalefactors_json.json\"])\n",
    "\n",
    "    if any(x is None for x in [mtx, feat, bc, pos]):\n",
    "        missing = [n for n,x in [(\"mtx\",mtx),(\"features\",feat),(\"barcodes\",bc),(\"positions\",pos)] if x is None]\n",
    "        raise FileNotFoundError(f\"{sample_id}: missing {missing}\")\n",
    "\n",
    "    with open_maybe_gz(mtx, \"rb\") as f:\n",
    "        X = mmread(f).T.tocsr()\n",
    "\n",
    "    feat_df = pd.read_csv(feat, sep=\"\\t\", header=None)\n",
    "    if feat_df.shape[1] >= 3:\n",
    "        feat_df = feat_df.iloc[:, :3].copy()\n",
    "        feat_df.columns = [\"gene_id\", \"gene_symbol\", \"feature_type\"]\n",
    "    elif feat_df.shape[1] == 2:\n",
    "        feat_df.columns = [\"gene_id\", \"gene_symbol\"]\n",
    "        feat_df[\"feature_type\"] = \"Gene Expression\"\n",
    "    else:\n",
    "        raise ValueError(f\"{sample_id}: unexpected features.tsv cols={feat_df.shape[1]}\")\n",
    "\n",
    "    feat_df[\"gene_id\"] = feat_df[\"gene_id\"].astype(str)\n",
    "    feat_df[\"gene_symbol\"] = feat_df[\"gene_symbol\"].astype(str)\n",
    "    feat_df[\"feature_type\"] = feat_df[\"feature_type\"].astype(str)\n",
    "\n",
    "    barcodes = pd.read_csv(bc, sep=\"\\t\", header=None, names=[\"barcode\"])\n",
    "    positions = pd.read_csv(\n",
    "        pos, header=None,\n",
    "        names=[\"barcode\",\"in_tissue\",\"array_row\",\"array_col\",\"pxl_row_in_fullres\",\"pxl_col_in_fullres\"]\n",
    "    )\n",
    "\n",
    "    a = ad.AnnData(X=X, obs=barcodes, var=feat_df)\n",
    "\n",
    "    a.var_names = a.var[\"gene_id\"].astype(str)\n",
    "    a.var_names_make_unique()\n",
    "\n",
    "    a.obs = a.obs.merge(positions, on=\"barcode\", how=\"left\")\n",
    "    a.obs.index = a.obs[\"barcode\"].astype(str)\n",
    "\n",
    "    a = a[a.obs[\"in_tissue\"] == 1, :].copy()\n",
    "    a.obsm[\"spatial\"] = a.obs[[\"pxl_row_in_fullres\",\"pxl_col_in_fullres\"]].to_numpy()\n",
    "\n",
    "    a.obs[\"sample_id\"] = sample_id\n",
    "    a.obs[\"gsm_id\"] = sample_id.split(\"_\")[0]\n",
    "\n",
    "    a.uns[\"scalefactors\"] = {}\n",
    "    if sf is not None:\n",
    "        with open_maybe_gz(sf, \"rt\") as f:\n",
    "            try:\n",
    "                a.uns[\"scalefactors\"] = json.load(f)\n",
    "            except Exception:\n",
    "                a.uns[\"scalefactors\"] = {}\n",
    "\n",
    "    return a\n",
    "\n",
    "\n",
    "# Detect sample IDs\n",
    "all_files = sorted([p.name for p in GSE_DIR.glob(\"*\") if p.is_file()])\n",
    "matrix_files = [f for f in all_files if f.endswith(\"_matrix.mtx.gz\") or f.endswith(\"_matrix.mtx\")]\n",
    "sample_ids = sorted(list({f.split(\"_matrix.mtx\")[0] for f in matrix_files}))\n",
    "log(f\"Detected Visium samples: {len(sample_ids)}\")\n",
    "if len(sample_ids) == 0:\n",
    "    raise RuntimeError(\"No _matrix.mtx(.gz) found in GSE folder.\")\n",
    "\n",
    "\n",
    "# Checksums (subset)\n",
    "to_hash = []\n",
    "for sid in sample_ids[:3]:\n",
    "    for suf in [\"_matrix.mtx.gz\",\"_matrix.mtx\",\"_features.tsv.gz\",\"_features.tsv\",\"_barcodes.tsv.gz\",\"_barcodes.tsv\",\n",
    "                \"_tissue_positions_list.csv.gz\",\"_tissue_positions_list.csv\",\"_scalefactors_json.json.gz\",\"_scalefactors_json.json\"]:\n",
    "        p = GSE_DIR / f\"{sid}{suf}\"\n",
    "        if p.exists():\n",
    "            to_hash.append(p)\n",
    "\n",
    "with open(CHK_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"# MD5 checksums (subset)\\n# Generated: {RUN_TS}\\n\\n\")\n",
    "    for p in to_hash:\n",
    "        try:\n",
    "            f.write(f\"{md5_file(p)}  {p.name}\\n\")\n",
    "        except Exception:\n",
    "            pass\n",
    "log(f\"Saved checksums: {CHK_PATH}\")\n",
    "\n",
    "\n",
    "# Load all samples\n",
    "adata_list = []\n",
    "for sid in sample_ids:\n",
    "    a = load_visium_components(sid, GSE_DIR)\n",
    "    adata_list.append(a)\n",
    "    log(f\"Loaded {sid}: spots={a.n_obs:,} genes={a.n_vars:,}\")\n",
    "\n",
    "adata = ad.concat(\n",
    "    adata_list,\n",
    "    label=\"sample_id_cat\",\n",
    "    keys=[a.obs[\"sample_id\"].iloc[0] for a in adata_list],\n",
    "    index_unique=\"_\",\n",
    "    join=\"inner\",\n",
    "    merge=\"same\"\n",
    ")\n",
    "\n",
    "log(f\"Combined spots={adata.n_obs:,} genes={adata.n_vars:,} samples={adata.obs['sample_id'].nunique()}\")\n",
    "log(f\"adata.var columns: {list(adata.var.columns)}\")\n",
    "\n",
    "tc0 = safe_sparse_sum(adata.X, axis=1)\n",
    "ng0 = safe_sparse_sum(adata.X > 0, axis=1)\n",
    "log(f\"Mean UMI/spot={tc0.mean():.1f} median genes/spot={np.median(ng0):.1f}\")\n",
    "\n",
    "\n",
    "# Supplementary Table 1\n",
    "rows = []\n",
    "for sid in sorted(adata.obs[\"sample_id\"].unique()):\n",
    "    a = adata[adata.obs[\"sample_id\"] == sid]\n",
    "    tc = safe_sparse_sum(a.X, axis=1)\n",
    "    ng = safe_sparse_sum(a.X > 0, axis=1)\n",
    "    rows.append({\n",
    "        \"Analysis_Date\": RUN_TS,\n",
    "        \"Sample_ID\": sid,\n",
    "        \"GSM_ID\": sid.split(\"_\")[0],\n",
    "        \"N_Spots\": int(a.n_obs),\n",
    "        \"Total_UMI\": int(tc.sum()),\n",
    "        \"Mean_UMI_per_Spot\": float(tc.mean()),\n",
    "        \"Median_Genes_per_Spot\": float(np.median(ng)),\n",
    "        \"Cancer_Type\": \"Cutaneous squamous cell carcinoma\",\n",
    "        \"Technology\": \"10x Visium\",\n",
    "        \"Treatment_Status\": \"Treatment-naïve\",\n",
    "        \"Dataset\": \"GSE289745\",\n",
    "    })\n",
    "supp1 = pd.DataFrame(rows)\n",
    "supp1_path = TABLES_DIR / \"Supplementary_Table_1.xlsx\"\n",
    "with pd.ExcelWriter(supp1_path, engine=\"openpyxl\") as w:\n",
    "    supp1.to_excel(w, index=False, sheet_name=\"Sample_Metadata\")\n",
    "log(f\"Saved {supp1_path}\")\n",
    "\n",
    "\n",
    "# QC metrics\n",
    "sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True)\n",
    "sym = adata.var[\"gene_symbol\"].astype(str).str.upper()\n",
    "adata.var[\"mt\"] = sym.str.startswith(\"MT-\")\n",
    "adata.var[\"ribo\"] = sym.str.match(r\"^RP[SL]\")\n",
    "sc.pp.calculate_qc_metrics(adata, qc_vars=[\"mt\",\"ribo\"], percent_top=None, log1p=False, inplace=True)\n",
    "\n",
    "def mad_bounds(x, n_mads=5):\n",
    "    med = np.median(x)\n",
    "    mad = median_abs_deviation(x)\n",
    "    return float(med - n_mads*mad), float(med + n_mads*mad)\n",
    "\n",
    "tc = adata.obs[\"total_counts\"].to_numpy()\n",
    "ng = adata.obs[\"n_genes_by_counts\"].to_numpy()\n",
    "mt = adata.obs[\"pct_counts_mt\"].to_numpy()\n",
    "\n",
    "tc_lo, tc_hi = mad_bounds(tc, 5)\n",
    "ng_lo, ng_hi = mad_bounds(ng, 5)\n",
    "tc_lo = max(tc_lo, 500.0)\n",
    "ng_lo = max(ng_lo, 200.0)\n",
    "\n",
    "mt_hi = 100.0 if int(adata.var[\"mt\"].sum()) == 0 else min(float(np.median(mt) + 5 * median_abs_deviation(mt)), 20.0)\n",
    "\n",
    "adata.uns[\"qc_thresholds\"] = {\n",
    "    \"total_counts_min\": tc_lo,\n",
    "    \"total_counts_max\": tc_hi,\n",
    "    \"n_genes_min\": ng_lo,\n",
    "    \"n_genes_max\": ng_hi,\n",
    "    \"pct_counts_mt_max\": mt_hi,\n",
    "    \"method\": \"MAD(5)+caps\"\n",
    "}\n",
    "log(f\"QC thresholds: counts [{tc_lo:.0f},{tc_hi:.0f}] genes [{ng_lo:.0f},{ng_hi:.0f}] mito<{mt_hi:.2f}%\")\n",
    "\n",
    "\n",
    "pass_mask = (\n",
    "    (adata.obs[\"total_counts\"] >= tc_lo) & (adata.obs[\"total_counts\"] <= tc_hi) &\n",
    "    (adata.obs[\"n_genes_by_counts\"] >= ng_lo) & (adata.obs[\"n_genes_by_counts\"] <= ng_hi) &\n",
    "    (adata.obs[\"pct_counts_mt\"] <= mt_hi)\n",
    ")\n",
    "\n",
    "n_spots_before = adata.n_obs\n",
    "adata = adata[pass_mask].copy()\n",
    "log(f\"Spot filter: {n_spots_before:,}->{adata.n_obs:,} ({adata.n_obs/n_spots_before*100:.1f}%)\")\n",
    "\n",
    "\n",
    "# Gene filter (>=1% spots)\n",
    "gene_n = safe_sparse_sum(adata.X > 0, axis=0)\n",
    "min_spots = max(1, int(0.01 * adata.n_obs))\n",
    "keep_gene = gene_n >= min_spots\n",
    "n_genes_before = adata.n_vars\n",
    "adata = adata[:, keep_gene].copy()\n",
    "\n",
    "# MT/ribo logging then removal\n",
    "sym = adata.var[\"gene_symbol\"].astype(str).str.upper()\n",
    "adata.var[\"mt\"] = sym.str.startswith(\"MT-\")\n",
    "adata.var[\"ribo\"] = sym.str.match(r\"^RP[SL]\")\n",
    "mt_before = int(adata.var[\"mt\"].sum())\n",
    "ribo_before = int(adata.var[\"ribo\"].sum())\n",
    "log(f\"MT genes before removal: {mt_before}\")\n",
    "log(f\"Ribo genes before removal: {ribo_before}\")\n",
    "\n",
    "adata = adata[:, ~(adata.var[\"mt\"] | adata.var[\"ribo\"])].copy()\n",
    "log(f\"Gene filter: {n_genes_before:,}->{adata.n_vars:,} (min_spots={min_spots}; removed MT/ribo={mt_before+ribo_before})\")\n",
    "\n",
    "\n",
    "# Batch check (fast)\n",
    "tmp = adata.copy()\n",
    "sc.pp.normalize_total(tmp, target_sum=1e4)\n",
    "sc.pp.log1p(tmp)\n",
    "sc.pp.highly_variable_genes(tmp, n_top_genes=2000, batch_key=\"sample_id\", flavor=\"seurat_v3\", layer=None)\n",
    "tmp = tmp[:, tmp.var[\"highly_variable\"]].copy()\n",
    "sc.pp.scale(tmp, max_value=10, zero_center=False)\n",
    "sc.tl.pca(tmp, n_comps=30, svd_solver=\"arpack\")\n",
    "sample_codes = pd.Categorical(tmp.obs[\"sample_id\"]).codes\n",
    "pc1_corr = spearmanr(tmp.obsm[\"X_pca\"][:, 0], sample_codes).correlation\n",
    "pc2_corr = spearmanr(tmp.obsm[\"X_pca\"][:, 1], sample_codes).correlation\n",
    "batch_flag = (abs(pc1_corr) > 0.5) or (abs(pc2_corr) > 0.5)\n",
    "adata.uns[\"batch_assessment\"] = {\"pc1_spearman\": float(pc1_corr), \"pc2_spearman\": float(pc2_corr), \"flag_strong\": bool(batch_flag)}\n",
    "log(f\"Batch check: PC1={pc1_corr:.3f} PC2={pc2_corr:.3f} strong={batch_flag}\")\n",
    "del tmp\n",
    "gc.collect()\n",
    "\n",
    "\n",
    "# Supplementary Figure 1\n",
    "sc.pp.calculate_qc_metrics(adata, percent_top=None, log1p=False, inplace=True)\n",
    "\n",
    "fig = plt.figure(figsize=(7.2, 4.6), dpi=SAVE_DPI)\n",
    "gs = fig.add_gridspec(2, 3, hspace=0.45, wspace=0.40)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0,0])\n",
    "ax1.boxplot(adata.obs[\"total_counts\"].values, showfliers=False)\n",
    "ax1.set_title(\"Total UMI\")\n",
    "ax1.set_ylabel(\"UMI\")\n",
    "ax1.set_xticks([])\n",
    "\n",
    "ax2 = fig.add_subplot(gs[0,1])\n",
    "ax2.boxplot(adata.obs[\"n_genes_by_counts\"].values, showfliers=False)\n",
    "ax2.set_title(\"Genes\")\n",
    "ax2.set_ylabel(\"Genes\")\n",
    "ax2.set_xticks([])\n",
    "\n",
    "ax3 = fig.add_subplot(gs[0,2])\n",
    "ax3.boxplot(adata.obs[\"pct_counts_mt\"].values, showfliers=False)\n",
    "ax3.axhline(y=mt_hi, linestyle=\"--\", linewidth=0.8)\n",
    "ax3.set_title(\"Mito %\")\n",
    "ax3.set_ylabel(\"%\")\n",
    "ax3.set_xticks([])\n",
    "\n",
    "ax4 = fig.add_subplot(gs[1,0])\n",
    "ax4.scatter(adata.obs[\"total_counts\"], adata.obs[\"n_genes_by_counts\"], s=1, alpha=0.20, rasterized=True)\n",
    "ax4.set_xlabel(\"UMI\")\n",
    "ax4.set_ylabel(\"Genes\")\n",
    "ax4.set_title(\"UMI vs Genes\")\n",
    "\n",
    "ax5 = fig.add_subplot(gs[1,1])\n",
    "ax5.scatter(adata.obs[\"total_counts\"], adata.obs[\"pct_counts_mt\"], s=1, alpha=0.20, rasterized=True)\n",
    "ax5.axhline(y=mt_hi, linestyle=\"--\", linewidth=0.8)\n",
    "ax5.set_xlabel(\"UMI\")\n",
    "ax5.set_ylabel(\"Mito %\")\n",
    "ax5.set_title(\"UMI vs Mito %\")\n",
    "\n",
    "ax6 = fig.add_subplot(gs[1,2])\n",
    "groups = [adata[adata.obs[\"sample_id\"] == s].obs[\"total_counts\"].values for s in sorted(adata.obs[\"sample_id\"].unique())]\n",
    "ax6.boxplot(groups, labels=[f\"S{i+1}\" for i in range(len(groups))], showfliers=False)\n",
    "ax6.set_title(\"UMI by sample\")\n",
    "ax6.set_ylabel(\"UMI\")\n",
    "ax6.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "fig.suptitle(\"Supplementary Figure 1: QC\", y=0.99)\n",
    "supp_fig1_path = FIGURES_DIR / \"Supplementary_Figure_1.png\"\n",
    "fig.savefig(supp_fig1_path, dpi=SAVE_DPI, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "log(f\"Saved {supp_fig1_path}\")\n",
    "\n",
    "\n",
    "# Preserve counts layer\n",
    "adata.layers[\"counts\"] = adata.X.copy()\n",
    "adata.raw = adata.copy()\n",
    "\n",
    "\n",
    "# Normalize + log1p\n",
    "sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "sc.pp.log1p(adata)\n",
    "adata.layers[\"log1p_norm\"] = adata.X.copy()\n",
    "log(\"Normalization done\")\n",
    "\n",
    "\n",
    "# HVGs from counts layer\n",
    "sc.pp.highly_variable_genes(\n",
    "    adata,\n",
    "    n_top_genes=3000,\n",
    "    batch_key=\"sample_id\",\n",
    "    flavor=\"seurat_v3\",\n",
    "    layer=\"counts\"\n",
    ")\n",
    "log(f\"HVGs: {int(adata.var['highly_variable'].sum())}\")\n",
    "\n",
    "\n",
    "# Spatial graphs\n",
    "def build_knn_graph_blockdiag(adata_in, k: int):\n",
    "    n = adata_in.n_obs\n",
    "    rows, cols, dists = [], [], []\n",
    "    for sid in sorted(adata_in.obs[\"sample_id\"].unique()):\n",
    "        idx = np.where(adata_in.obs[\"sample_id\"].values == sid)[0]\n",
    "        coords = adata_in.obsm[\"spatial\"][idx]\n",
    "        if len(idx) <= 2:\n",
    "            continue\n",
    "        nn = NearestNeighbors(n_neighbors=min(k+1, len(idx)), algorithm=\"auto\").fit(coords)\n",
    "        dist, nbr = nn.kneighbors(coords)\n",
    "        for i_local in range(len(idx)):\n",
    "            i = idx[i_local]\n",
    "            for j_pos in range(1, nbr.shape[1]):\n",
    "                j = idx[nbr[i_local, j_pos]]\n",
    "                rows.append(i); cols.append(j); dists.append(float(dist[i_local, j_pos]))\n",
    "    A = sp.csr_matrix((np.ones(len(rows), dtype=np.float32), (rows, cols)), shape=(n, n))\n",
    "    D = sp.csr_matrix((np.array(dists, dtype=np.float32), (rows, cols)), shape=(n, n))\n",
    "    A = A.maximum(A.T)\n",
    "    D = D.maximum(D.T)\n",
    "    return A, D\n",
    "\n",
    "def build_delaunay_graph_blockdiag(adata_in):\n",
    "    n = adata_in.n_obs\n",
    "    rows, cols = [], []\n",
    "    skipped = []\n",
    "    for sid in sorted(adata_in.obs[\"sample_id\"].unique()):\n",
    "        idx = np.where(adata_in.obs[\"sample_id\"].values == sid)[0]\n",
    "        coords = adata_in.obsm[\"spatial\"][idx]\n",
    "        if len(idx) < 4:\n",
    "            skipped.append((sid, \"too_few_points\"))\n",
    "            continue\n",
    "        try:\n",
    "            tri = Delaunay(coords, qhull_options=\"QJ\")\n",
    "            simplices = tri.simplices\n",
    "            for s in simplices:\n",
    "                pairs = [(s[0],s[1]),(s[1],s[2]),(s[0],s[2])]\n",
    "                for a,b in pairs:\n",
    "                    rows.append(idx[a]); cols.append(idx[b])\n",
    "                    rows.append(idx[b]); cols.append(idx[a])\n",
    "        except Exception as e:\n",
    "            skipped.append((sid, f\"qhull_fail:{type(e).__name__}\"))\n",
    "            continue\n",
    "\n",
    "    A = sp.csr_matrix((np.ones(len(rows), dtype=np.float32), (rows, cols)), shape=(n, n))\n",
    "    A = A.maximum(A.T)\n",
    "    coords_all = adata_in.obsm[\"spatial\"]\n",
    "    rr, cc = A.nonzero()\n",
    "    dist = np.sqrt(((coords_all[rr] - coords_all[cc])**2).sum(axis=1)).astype(np.float32)\n",
    "    D = sp.csr_matrix((dist, (rr, cc)), shape=(n, n))\n",
    "    return A, D, skipped\n",
    "\n",
    "log(\"Building spatial graphs...\")\n",
    "A6, D6 = build_knn_graph_blockdiag(adata, 6)\n",
    "A10, D10 = build_knn_graph_blockdiag(adata, 10)\n",
    "Adel, Ddel, del_skipped = build_delaunay_graph_blockdiag(adata)\n",
    "\n",
    "adata.obsp[\"spatial_k6_connectivities\"] = A6\n",
    "adata.obsp[\"spatial_k6_distances\"] = D6\n",
    "adata.obsp[\"spatial_k10_connectivities\"] = A10\n",
    "adata.obsp[\"spatial_k10_distances\"] = D10\n",
    "adata.obsp[\"spatial_delaunay_connectivities\"] = Adel\n",
    "adata.obsp[\"spatial_delaunay_distances\"] = Ddel\n",
    "adata.obsp[\"spatial_connectivities\"] = A6.copy()\n",
    "adata.obsp[\"spatial_distances\"] = D6.copy()\n",
    "\n",
    "\n",
    "# µm↔px calibration\n",
    "VISIUM_SPOT_DIAMETER_UM = 55.0\n",
    "scale_by_sample = {}\n",
    "missing_sf = 0\n",
    "for sid in sorted(adata.obs[\"sample_id\"].unique()):\n",
    "    sf_path = find_existing(GSE_DIR, [f\"{sid}_scalefactors_json.json.gz\", f\"{sid}_scalefactors_json.json\"])\n",
    "    if sf_path is None:\n",
    "        missing_sf += 1\n",
    "        continue\n",
    "    with open_maybe_gz(sf_path, \"rt\") as f:\n",
    "        sf = json.load(f)\n",
    "    spot_diam_px = sf.get(\"spot_diameter_fullres\")\n",
    "    um_per_px = VISIUM_SPOT_DIAMETER_UM / float(spot_diam_px)\n",
    "    px_per_um = 1.0 / um_per_px\n",
    "    scale_by_sample[sid] = {\n",
    "        \"spot_diameter_fullres_px\": float(spot_diam_px),\n",
    "        \"um_per_px\": float(um_per_px),\n",
    "        \"px_per_um\": float(px_per_um)\n",
    "    }\n",
    "\n",
    "adata.uns[\"spatial_scale\"] = {\"visium_spot_diameter_um_assumed\": VISIUM_SPOT_DIAMETER_UM, \"per_sample\": scale_by_sample}\n",
    "log(f\"Spatial scale missing scalefactors: {missing_sf}\")\n",
    "\n",
    "perineural_thresholds_um = [50, 100, 200, 500]\n",
    "adata.uns[\"perineural_thresholds_um\"] = perineural_thresholds_um\n",
    "adata.uns[\"perineural_thresholds_px_by_sample\"] = {\n",
    "    sid: {f\"{u}um\": float(u * scale_by_sample[sid][\"px_per_um\"]) for u in perineural_thresholds_um}\n",
    "    for sid in scale_by_sample.keys()\n",
    "}\n",
    "\n",
    "\n",
    "# Moran's I \n",
    "def morans_i_sparse(X, W_csr, n_perms=100, seed=42):\n",
    "    # X: (n, g) dense float32; W_csr: row-normalized sparse\n",
    "    rng = np.random.default_rng(seed)\n",
    "    n, g = X.shape\n",
    "    # center\n",
    "    Xc = X - X.mean(axis=0, keepdims=True)\n",
    "    denom = (Xc * Xc).sum(axis=0)\n",
    "    denom = np.where(denom == 0, np.nan, denom)\n",
    "\n",
    "    WX = W_csr @ Xc  # (n, g)\n",
    "    num = (Xc * WX).sum(axis=0)\n",
    "    I = (n * num) / denom  # since sum(W)=n for row-normalized\n",
    "\n",
    "    p = np.full(g, np.nan, dtype=float)\n",
    "    if n_perms > 0:\n",
    "        ge = np.zeros(g, dtype=int)\n",
    "        for _ in range(n_perms):\n",
    "            perm = rng.permutation(n)\n",
    "            Xp = Xc[perm, :]\n",
    "            WXp = W_csr @ Xp\n",
    "            nump = (Xp * WXp).sum(axis=0)\n",
    "            Ip = (n * nump) / denom\n",
    "            ge += (np.abs(Ip) >= np.abs(I)).astype(int)\n",
    "        p = (ge + 1.0) / (n_perms + 1.0)\n",
    "\n",
    "    return I.astype(float), p.astype(float)\n",
    "\n",
    "def bh_fdr(pvals):\n",
    "    p = np.asarray(pvals, dtype=float)\n",
    "    m = np.sum(np.isfinite(p))\n",
    "    q = np.full_like(p, np.nan, dtype=float)\n",
    "    if m == 0:\n",
    "        return q\n",
    "    idx = np.where(np.isfinite(p))[0]\n",
    "    pv = p[idx]\n",
    "    order = np.argsort(pv)\n",
    "    pv_sorted = pv[order]\n",
    "    ranks = np.arange(1, m+1)\n",
    "    q_sorted = pv_sorted * m / ranks\n",
    "    q_sorted = np.minimum.accumulate(q_sorted[::-1])[::-1]\n",
    "    q[idx[order]] = np.clip(q_sorted, 0, 1)\n",
    "    return q\n",
    "\n",
    "# Build row-normalized W from k6 adjacency\n",
    "W = A6.tocsr().astype(np.float32)\n",
    "row_sums = np.asarray(W.sum(axis=1)).ravel().astype(np.float32)\n",
    "row_sums[row_sums == 0] = 1.0\n",
    "W = sp.diags(1.0 / row_sums) @ W  # row-normalize\n",
    "\n",
    "# Pick top 500 HVGs by dispersions_norm\n",
    "hv_mask = adata.var[\"highly_variable\"].values\n",
    "hvg_idx = np.where(hv_mask)[0]\n",
    "if \"dispersions_norm\" in adata.var.columns:\n",
    "    disp = adata.var[\"dispersions_norm\"].to_numpy()\n",
    "    hvg_idx = hvg_idx[np.argsort(disp[hvg_idx])[::-1]]\n",
    "top_n = 500\n",
    "top_hvg_idx = hvg_idx[:min(top_n, len(hvg_idx))]\n",
    "top_hvg_names = adata.var_names[top_hvg_idx]\n",
    "\n",
    "# Use log1p normalized expression for Moran\n",
    "X_moran = adata[:, top_hvg_names].X\n",
    "if sp.issparse(X_moran):\n",
    "    X_moran = X_moran.toarray()\n",
    "X_moran = X_moran.astype(np.float32)\n",
    "\n",
    "log(f\"Moran's I: genes={X_moran.shape[1]} perms=100\")\n",
    "I, pvals = morans_i_sparse(X_moran, W, n_perms=100, seed=RANDOM_SEED)\n",
    "qvals = bh_fdr(pvals)\n",
    "\n",
    "# Store Moran into adata.var for those genes\n",
    "adata.var[\"morans_i\"] = np.nan\n",
    "adata.var[\"morans_p\"] = np.nan\n",
    "adata.var[\"morans_q\"] = np.nan\n",
    "adata.var.loc[top_hvg_names, \"morans_i\"] = I\n",
    "adata.var.loc[top_hvg_names, \"morans_p\"] = pvals\n",
    "adata.var.loc[top_hvg_names, \"morans_q\"] = qvals\n",
    "\n",
    "\n",
    "# Supplementary Table 2 (HVGs + Moran info where available)\n",
    "hvg_df = adata.var.loc[adata.var[\"highly_variable\"]].copy()\n",
    "hvg_df[\"var_id\"] = hvg_df.index.astype(str)\n",
    "cols = [c for c in [\"var_id\",\"gene_id\",\"gene_symbol\",\"feature_type\",\"means\",\"dispersions\",\"dispersions_norm\",\"morans_i\",\"morans_p\",\"morans_q\"] if c in hvg_df.columns]\n",
    "supp2 = hvg_df[cols].copy()\n",
    "if \"dispersions_norm\" in supp2.columns:\n",
    "    supp2 = supp2.sort_values(\"dispersions_norm\", ascending=False)\n",
    "supp2_path = TABLES_DIR / \"Supplementary_Table_2.xlsx\"\n",
    "with pd.ExcelWriter(supp2_path, engine=\"openpyxl\") as w:\n",
    "    supp2.to_excel(w, index=False, sheet_name=\"HVG_Moran\")\n",
    "log(f\"Saved {supp2_path}\")\n",
    "\n",
    "\n",
    "# Embeddings for Main Figure 1\n",
    "sc.pp.scale(adata, max_value=10)\n",
    "sc.tl.pca(adata, n_comps=50, use_highly_variable=True, svd_solver=\"arpack\")\n",
    "\n",
    "var_ratio = adata.uns[\"pca\"][\"variance_ratio\"]\n",
    "cum = np.cumsum(var_ratio)\n",
    "n_pcs = int(np.where(cum > 0.8)[0][0] + 1) if np.any(cum > 0.8) else 30\n",
    "n_pcs_use = min(n_pcs, 30)\n",
    "adata.uns[\"n_pcs_use\"] = n_pcs_use\n",
    "\n",
    "sc.pp.neighbors(adata, n_neighbors=15, n_pcs=n_pcs_use)\n",
    "sc.tl.umap(adata)\n",
    "sc.tl.leiden(adata, resolution=0.5, key_added=\"leiden_r0.5\")\n",
    "\n",
    "rep_sample = sorted(adata.obs[\"sample_id\"].unique())[0]\n",
    "rep = adata[adata.obs[\"sample_id\"] == rep_sample].copy()\n",
    "\n",
    "\n",
    "# Main Figure\n",
    "# Panel A: legend below; Panel B: cluster labels at centroids (no legend)\n",
    "fig = plt.figure(figsize=(7.2, 2.4), dpi=SAVE_DPI)\n",
    "gs = fig.add_gridspec(1, 3, wspace=0.35)\n",
    "\n",
    "ax1 = fig.add_subplot(gs[0,0])\n",
    "handles_A = []\n",
    "labels_A = []\n",
    "for s in sorted(adata.obs[\"sample_id\"].unique()):\n",
    "    m = (adata.obs[\"sample_id\"] == s).to_numpy()\n",
    "    h = ax1.scatter(adata.obsm[\"X_umap\"][m,0], adata.obsm[\"X_umap\"][m,1], s=2, alpha=0.7, label=s, rasterized=True)\n",
    "    handles_A.append(h); labels_A.append(s)\n",
    "ax1.set_title(\"A  UMAP by sample\")\n",
    "ax1.set_xlabel(\"UMAP1\")\n",
    "ax1.set_ylabel(\"UMAP2\")\n",
    "\n",
    "# Put legend below the axis\n",
    "legA = ax1.legend(\n",
    "    loc=\"upper center\",\n",
    "    bbox_to_anchor=(0.5, -0.20),\n",
    "    ncol=2,\n",
    "    frameon=False,\n",
    "    handletextpad=0.3,\n",
    "    columnspacing=0.8,\n",
    "    borderaxespad=0.0,\n",
    "    markerscale=2.5\n",
    ")\n",
    "\n",
    "ax2 = fig.add_subplot(gs[0,1])\n",
    "# Plot points colored by cluster\n",
    "clusters = adata.obs[\"leiden_r0.5\"].astype(str).values\n",
    "uniq = sorted(np.unique(clusters), key=lambda x: int(x) if x.isdigit() else x)\n",
    "# stable color map\n",
    "cmap = plt.cm.tab20\n",
    "colors = {c: cmap(i % 20) for i, c in enumerate(uniq)}\n",
    "for c in uniq:\n",
    "    m = (clusters == c)\n",
    "    ax2.scatter(adata.obsm[\"X_umap\"][m,0], adata.obsm[\"X_umap\"][m,1], s=2, alpha=0.7, color=colors[c], rasterized=True)\n",
    "\n",
    "# Annotate cluster IDs at centroids\n",
    "for c in uniq:\n",
    "    m = (clusters == c)\n",
    "    if m.sum() < 50:\n",
    "        continue\n",
    "    x = np.median(adata.obsm[\"X_umap\"][m,0])\n",
    "    y = np.median(adata.obsm[\"X_umap\"][m,1])\n",
    "    t = ax2.text(x, y, c, ha=\"center\", va=\"center\", fontsize=6, color=\"black\")\n",
    "    t.set_path_effects([pe.withStroke(linewidth=2.0, foreground=\"white\")])\n",
    "\n",
    "ax2.set_title(\"B  UMAP by Leiden\")\n",
    "ax2.set_xlabel(\"UMAP1\")\n",
    "ax2.set_ylabel(\"UMAP2\")\n",
    "\n",
    "ax3 = fig.add_subplot(gs[0,2])\n",
    "coords = rep.obsm[\"spatial\"]\n",
    "tc_rep = rep.obs[\"total_counts\"].to_numpy()\n",
    "scat = ax3.scatter(coords[:,1], coords[:,0], c=tc_rep, s=5, alpha=0.9, rasterized=True)\n",
    "ax3.invert_yaxis()\n",
    "ax3.set_title(\"C  Spatial Total UMI\\n\" + rep_sample)\n",
    "ax3.set_xlabel(\"X\")\n",
    "ax3.set_ylabel(\"Y\")\n",
    "cbar = fig.colorbar(scat, ax=ax3, fraction=0.05, pad=0.02)\n",
    "cbar.set_label(\"Total UMI\")\n",
    "\n",
    "# Give bottom space for Panel A legend\n",
    "fig.subplots_adjust(bottom=0.28)\n",
    "\n",
    "main_fig1_path = FIGURES_DIR / \"Main_Figure_1.png\"\n",
    "fig.savefig(main_fig1_path, dpi=SAVE_DPI, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "log(f\"Saved {main_fig1_path}\")\n",
    "\n",
    "\n",
    "# Benchmark + Supplementary Figure 2\n",
    "def bench_step(fn, label):\n",
    "    mem0 = psutil.Process(os.getpid()).memory_info().rss\n",
    "    t0 = time.time()\n",
    "    fn()\n",
    "    t1 = time.time()\n",
    "    mem1 = psutil.Process(os.getpid()).memory_info().rss\n",
    "    return {\"step\": label, \"time_sec\": float(t1-t0), \"mem_delta_mb\": float((mem1-mem0)/(1024**2))}\n",
    "\n",
    "bench_rows = []\n",
    "n_total = adata.n_obs\n",
    "for frac in [0.10, 0.25, 0.50, 1.00]:\n",
    "    if frac < 1.0:\n",
    "        n_sub = int(n_total * frac)\n",
    "        idx = np.random.choice(n_total, n_sub, replace=False)\n",
    "        a_sub = adata[idx].copy()\n",
    "        label = f\"{int(frac*100)}%\"\n",
    "    else:\n",
    "        a_sub = adata.copy()\n",
    "        label = \"100%\"\n",
    "\n",
    "    def step_spatial_k6():\n",
    "        _A, _D = build_knn_graph_blockdiag(a_sub, 6)\n",
    "        _ = _A.nnz + _D.nnz\n",
    "\n",
    "    def step_pca30():\n",
    "        sc.pp.scale(a_sub, max_value=10)\n",
    "        sc.tl.pca(a_sub, n_comps=30, svd_solver=\"arpack\")\n",
    "\n",
    "    gc.collect()\n",
    "    r1 = bench_step(step_spatial_k6, f\"{label}_spatial_k6\")\n",
    "    gc.collect()\n",
    "    r2 = bench_step(step_pca30, f\"{label}_pca\")\n",
    "    r1[\"spots\"] = int(a_sub.n_obs); r2[\"spots\"] = int(a_sub.n_obs)\n",
    "    bench_rows.extend([r1, r2])\n",
    "\n",
    "bench_df = pd.DataFrame(bench_rows)\n",
    "supp3_path = TABLES_DIR / \"Supplementary_Table_3.xlsx\"\n",
    "with pd.ExcelWriter(supp3_path, engine=\"openpyxl\") as w:\n",
    "    bench_df.to_excel(w, index=False, sheet_name=\"Benchmark\")\n",
    "log(f\"Saved {supp3_path}\")\n",
    "\n",
    "fig = plt.figure(figsize=(7.2, 2.4), dpi=SAVE_DPI)\n",
    "gs = fig.add_gridspec(1, 2, wspace=0.35)\n",
    "ax1 = fig.add_subplot(gs[0,0])\n",
    "ax2 = fig.add_subplot(gs[0,1])\n",
    "\n",
    "t1 = bench_df[bench_df[\"step\"].str.contains(\"spatial_k6\")].copy()\n",
    "t2 = bench_df[bench_df[\"step\"].str.contains(\"_pca\")].copy()\n",
    "\n",
    "ax1.plot(t1[\"spots\"], t1[\"time_sec\"], marker=\"o\")\n",
    "ax1.set_title(\"Spatial k6 runtime\")\n",
    "ax1.set_xlabel(\"Spots\")\n",
    "ax1.set_ylabel(\"Sec\")\n",
    "\n",
    "ax2.plot(t2[\"spots\"], t2[\"time_sec\"], marker=\"o\")\n",
    "ax2.set_title(\"PCA runtime\")\n",
    "ax2.set_xlabel(\"Spots\")\n",
    "ax2.set_ylabel(\"Sec\")\n",
    "\n",
    "supp_fig2_path = FIGURES_DIR / \"Supplementary_Figure_2.png\"\n",
    "fig.savefig(supp_fig2_path, dpi=SAVE_DPI, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "log(f\"Saved {supp_fig2_path}\")\n",
    "\n",
    "\n",
    "# Save processed artifacts\n",
    "adata.obs.index.name = \"obs_id\"  \n",
    "\n",
    "adata_path = PROCESSED_DIR / \"processed_spatial_adata.h5ad\"\n",
    "adata.write_h5ad(adata_path)\n",
    "\n",
    "graphs = {\n",
    "    \"spatial_k6_connectivities\": adata.obsp[\"spatial_k6_connectivities\"],\n",
    "    \"spatial_k6_distances\": adata.obsp[\"spatial_k6_distances\"],\n",
    "    \"spatial_k10_connectivities\": adata.obsp[\"spatial_k10_connectivities\"],\n",
    "    \"spatial_k10_distances\": adata.obsp[\"spatial_k10_distances\"],\n",
    "    \"spatial_delaunay_connectivities\": adata.obsp[\"spatial_delaunay_connectivities\"],\n",
    "    \"spatial_delaunay_distances\": adata.obsp[\"spatial_delaunay_distances\"],\n",
    "    \"default_connectivities\": adata.obsp[\"spatial_connectivities\"],\n",
    "    \"default_distances\": adata.obsp[\"spatial_distances\"],\n",
    "    \"qc_thresholds\": adata.uns.get(\"qc_thresholds\"),\n",
    "    \"batch_assessment\": adata.uns.get(\"batch_assessment\"),\n",
    "    \"spatial_scale\": adata.uns.get(\"spatial_scale\"),\n",
    "    \"perineural_thresholds_um\": adata.uns.get(\"perineural_thresholds_um\"),\n",
    "    \"perineural_thresholds_px_by_sample\": adata.uns.get(\"perineural_thresholds_px_by_sample\"),\n",
    "    \"delaunay_skipped\": del_skipped,\n",
    "}\n",
    "graphs_path = PROCESSED_DIR / \"spatial_graphs.pkl\"\n",
    "with open(graphs_path, \"wb\") as f:\n",
    "    pickle.dump(graphs, f)\n",
    "\n",
    "checklist = [\n",
    "    \"Notebook 1 reproducibility checklist\",\n",
    "    f\"Run timestamp: {RUN_TS}\",\n",
    "    f\"Seed: {RANDOM_SEED}\",\n",
    "    \"Manuscript outputs:\",\n",
    "    str(FIGURES_DIR / \"Main_Figure_1.png\"),\n",
    "    str(FIGURES_DIR / \"Supplementary_Figure_1.png\"),\n",
    "    str(FIGURES_DIR / \"Supplementary_Figure_2.png\"),\n",
    "    str(TABLES_DIR / \"Supplementary_Table_1.xlsx\"),\n",
    "    str(TABLES_DIR / \"Supplementary_Table_2.xlsx\"),\n",
    "    str(TABLES_DIR / \"Supplementary_Table_3.xlsx\"),\n",
    "    \"Intermediate outputs:\",\n",
    "    str(adata_path),\n",
    "    str(graphs_path),\n",
    "    str(REQ_PATH),\n",
    "    str(LOG_PATH),\n",
    "    str(CHK_PATH),\n",
    "]\n",
    "CHECKLIST_PATH.write_text(\"\\n\".join(checklist), encoding=\"utf-8\")\n",
    "\n",
    "log(f\"Saved {adata_path}\")\n",
    "log(f\"Saved {graphs_path}\")\n",
    "log(f\"Saved {CHECKLIST_PATH}\")\n",
    "log(f\"End: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print(\"\\nDone.\")\n",
    "print(\"Figures:\", FIGURES_DIR)\n",
    "print(\"Tables :\", TABLES_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60462983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notebook 2: Nerve Injury Signature Derivation, Validation & Benchmarking\n",
    "\n",
    "import os, sys, platform, time, json, pickle, warnings, gc\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve, f1_score, roc_auc_score\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import anndata as ad\n",
    "import scanpy as sc\n",
    "import psutil\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "sc.settings.verbosity = 2\n",
    "sc.settings.n_jobs = -1\n",
    "\n",
    "# Optional enrichment\n",
    "try:\n",
    "    import gseapy as gp\n",
    "    HAS_GSEAPY = True\n",
    "except Exception:\n",
    "    HAS_GSEAPY = False\n",
    "\n",
    "# Repro + paths\n",
    "RUN_TS = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "import random\n",
    "random.seed(RANDOM_SEED)\n",
    "\n",
    "SAVE_DPI = 1200\n",
    "VERSION = \"v1.0\"\n",
    "\n",
    "BASE_DIR = Path(r\"D:\\个人文件夹\\Sanwal\\Neuro\")\n",
    "MANUSCRIPT_DIR = BASE_DIR / \"Manuscript Data\"\n",
    "FIGURES_DIR = MANUSCRIPT_DIR / \"Figures\"\n",
    "TABLES_DIR = MANUSCRIPT_DIR / \"Tables\"\n",
    "NB1_DIR = BASE_DIR / \"processed\" / \"notebook1\"\n",
    "PROCESSED_DIR = BASE_DIR / \"processed\" / \"notebook2\"\n",
    "for d in [FIGURES_DIR, TABLES_DIR, PROCESSED_DIR]:\n",
    "    d.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LOG_PATH = PROCESSED_DIR / \"run_log.txt\"\n",
    "\n",
    "def set_n_style():\n",
    "    mpl.rcParams.update({\n",
    "        \"font.family\": \"sans-serif\",\n",
    "        \"font.sans-serif\": [\"Arial\", \"Helvetica\", \"DejaVu Sans\"],\n",
    "        \"font.size\": 7,\n",
    "        \"axes.titlesize\": 7,\n",
    "        \"axes.labelsize\": 7,\n",
    "        \"xtick.labelsize\": 6,\n",
    "        \"ytick.labelsize\": 6,\n",
    "        \"legend.fontsize\": 6,\n",
    "        \"axes.linewidth\": 0.6,\n",
    "        \"lines.linewidth\": 0.8,\n",
    "        \"xtick.major.width\": 0.6,\n",
    "        \"ytick.major.width\": 0.6,\n",
    "        \"xtick.direction\": \"in\",\n",
    "        \"ytick.direction\": \"in\",\n",
    "        \"savefig.dpi\": SAVE_DPI,\n",
    "        \"pdf.fonttype\": 42,\n",
    "        \"ps.fonttype\": 42,\n",
    "    })\n",
    "set_n_style()\n",
    "\n",
    "def log(msg: str):\n",
    "    print(msg)\n",
    "    with open(LOG_PATH, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(msg.rstrip() + \"\\n\")\n",
    "\n",
    "with open(LOG_PATH, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"PeriNeuroImmuneMap Notebook 2 log\\n\")\n",
    "    f.write(f\"Start: {RUN_TS}\\n\")\n",
    "\n",
    "log(f\"Python: {sys.version.split()[0]}\")\n",
    "log(f\"Platform: {platform.platform()}\")\n",
    "log(f\"Seed: {RANDOM_SEED}\")\n",
    "log(f\"CPU logical: {psutil.cpu_count(True)} | CPU physical: {psutil.cpu_count(False)}\")\n",
    "log(f\"RAM total GB: {psutil.virtual_memory().total/(1024**3):.2f}\")\n",
    "log(f\"scanpy: {sc.__version__} | anndata: {ad.__version__}\")\n",
    "log(f\"gseapy: {'yes' if HAS_GSEAPY else 'no'}\")\n",
    "\n",
    "# Helpers\n",
    "def safe_mean(X, axis=0):\n",
    "    if sp.issparse(X):\n",
    "        return np.asarray(X.mean(axis=axis)).ravel()\n",
    "    return np.mean(X, axis=axis)\n",
    "\n",
    "def safe_sum(X, axis=0):\n",
    "    if sp.issparse(X):\n",
    "        return np.asarray(X.sum(axis=axis)).ravel()\n",
    "    return np.sum(X, axis=axis)\n",
    "\n",
    "def get_layer(adata_obj: ad.AnnData, layer_name: str):\n",
    "    if layer_name is None or layer_name == \"X\":\n",
    "        return adata_obj.X\n",
    "    if layer_name in adata_obj.layers:\n",
    "        return adata_obj.layers[layer_name]\n",
    "    return adata_obj.X\n",
    "\n",
    "def find_genes_in_adata(genes: List[str], adata_var: pd.DataFrame) -> List[str]:\n",
    "    \"\"\"\n",
    "    Return var_names (gene_id) for requested gene SYMBOLS (case-insensitive),\n",
    "    falling back to matching var_names directly.\n",
    "    \"\"\"\n",
    "    found = []\n",
    "    if \"gene_symbol\" in adata_var.columns:\n",
    "        sym = adata_var[\"gene_symbol\"].astype(str).str.upper()\n",
    "    else:\n",
    "        sym = pd.Series([\"\"] * adata_var.shape[0], index=adata_var.index, dtype=str)\n",
    "\n",
    "    var_upper = pd.Index(adata_var.index.astype(str).str.upper())\n",
    "\n",
    "    for g in genes:\n",
    "        gu = str(g).upper()\n",
    "        # symbol match\n",
    "        hit = sym[sym == gu]\n",
    "        if len(hit) > 0:\n",
    "            found.append(hit.index[0])\n",
    "            continue\n",
    "        # varname match\n",
    "        if gu in var_upper:\n",
    "            idx = var_upper.get_loc(gu)\n",
    "            found.append(adata_var.index[idx])\n",
    "    return list(pd.unique(found))\n",
    "\n",
    "def morans_I_sparse(score: np.ndarray, W: sp.csr_matrix) -> float:\n",
    "    \"\"\"\n",
    "    Classic Moran's I using unstandardized W:\n",
    "      I = (n / S0) * (x^T W x) / (x^T x), where x is mean-centered.\n",
    "    \"\"\"\n",
    "    x = score.astype(np.float64)\n",
    "    x = x - x.mean()\n",
    "    denom = float(np.dot(x, x))\n",
    "    if denom <= 0:\n",
    "        return np.nan\n",
    "    S0 = float(W.sum())\n",
    "    if S0 <= 0:\n",
    "        return np.nan\n",
    "    Wx = W.dot(x)\n",
    "    num = float(np.dot(x, Wx))\n",
    "    n = x.shape[0]\n",
    "    return float((n / S0) * (num / denom))\n",
    "\n",
    "def score_mean_z(adata_obj: ad.AnnData, genes_varnames: List[str], layer=\"log1p_norm\") -> np.ndarray:\n",
    "    X = get_layer(adata_obj, layer)\n",
    "    genes = [g for g in genes_varnames if g in adata_obj.var_names]\n",
    "    if len(genes) == 0:\n",
    "        return np.zeros(adata_obj.n_obs, dtype=np.float32)\n",
    "    idx = [adata_obj.var_names.get_loc(g) for g in genes]\n",
    "    if sp.issparse(X):\n",
    "        Xsub = X[:, idx].toarray()\n",
    "    else:\n",
    "        Xsub = X[:, idx]\n",
    "    mu = Xsub.mean(axis=0)\n",
    "    sd = Xsub.std(axis=0) + 1e-9\n",
    "    Z = (Xsub - mu) / sd\n",
    "    return Z.mean(axis=1).astype(np.float32)\n",
    "\n",
    "def score_weighted_mean(adata_obj: ad.AnnData, genes_varnames: List[str], weights: Dict[str, float], layer=\"log1p_norm\") -> np.ndarray:\n",
    "    X = get_layer(adata_obj, layer)\n",
    "    genes = [g for g in genes_varnames if g in adata_obj.var_names and g in weights]\n",
    "    if len(genes) == 0:\n",
    "        return np.zeros(adata_obj.n_obs, dtype=np.float32)\n",
    "    idx = [adata_obj.var_names.get_loc(g) for g in genes]\n",
    "    w = np.array([weights[g] for g in genes], dtype=np.float32)\n",
    "    wsum = float(np.sum(np.abs(w))) if float(np.sum(np.abs(w))) > 0 else 1.0\n",
    "    if sp.issparse(X):\n",
    "        Xsub = X[:, idx].toarray().astype(np.float32)\n",
    "    else:\n",
    "        Xsub = X[:, idx].astype(np.float32)\n",
    "    # weights can be signed; normalize by sum(|w|) to keep scale stable\n",
    "    return (Xsub @ w / wsum).astype(np.float32)\n",
    "\n",
    "# Load NB1 output\n",
    "adata_path = NB1_DIR / \"processed_spatial_adata.h5ad\"\n",
    "if not adata_path.exists():\n",
    "    raise FileNotFoundError(f\"Run Notebook 1 first: {adata_path}\")\n",
    "\n",
    "log(f\"Loading: {adata_path}\")\n",
    "adata = ad.read_h5ad(adata_path)\n",
    "log(f\"Loaded: spots={adata.n_obs:,} genes={adata.n_vars:,} samples={adata.obs['sample_id'].nunique()}\")\n",
    "log(f\"Layers: {list(adata.layers.keys())}\")\n",
    "\n",
    "if \"counts\" not in adata.layers:\n",
    "    raise ValueError(\"Notebook 1 must save adata.layers['counts'] (raw counts).\")\n",
    "if \"log1p_norm\" not in adata.layers:\n",
    "    raise ValueError(\"Notebook 1 must save adata.layers['log1p_norm'] (log1p normalized).\")\n",
    "\n",
    "# Graph\n",
    "if \"spatial_connectivities\" in adata.obsp:\n",
    "    W = adata.obsp[\"spatial_connectivities\"].tocsr()\n",
    "elif \"spatial_k6_connectivities\" in adata.obsp:\n",
    "    W = adata.obsp[\"spatial_k6_connectivities\"].tocsr()\n",
    "else:\n",
    "    raise ValueError(\"No spatial connectivity matrix found in adata.obsp (need kNN graph from Notebook 1).\")\n",
    "\n",
    "W.sum_duplicates()\n",
    "W.eliminate_zeros()\n",
    "\n",
    "# Parameters\n",
    "PARAMS = {\n",
    "    \"nerve_region_top_percent\": 10.0,\n",
    "    \"min_markers_for_nerve\": 2,\n",
    "    \"de_method\": \"wilcoxon\",\n",
    "    \"de_log2fc_threshold\": 0.5,\n",
    "    \"de_padj_threshold\": 0.05,\n",
    "    \"signature_sizes\": [50, 100, 200, 500],\n",
    "    \"n_bootstrap\": 100,\n",
    "    \"n_permutations\": 1000,\n",
    "    \"perm_log_every\": 200,\n",
    "}\n",
    "\n",
    "log(\"PARAMS: \" + json.dumps(PARAMS, indent=2))\n",
    "\n",
    "# Canonical markers + stress sets\n",
    "CANONICAL_NERVE_MARKERS = [\"ATF3\",\"JUN\",\"SOX11\",\"GAP43\",\"SPRR1A\",\"NEFM\",\"NEFL\"]\n",
    "\n",
    "GENERIC_STRESS_SETS = {\n",
    "    \"Heat_Shock\": [\"HSPA1A\",\"HSPA1B\",\"HSPA6\",\"HSPA8\",\"HSP90AA1\",\"HSP90AB1\",\"HSPB1\",\"HSPH1\",\"DNAJA1\",\"DNAJB1\"],\n",
    "    \"Hypoxia\": [\"HIF1A\",\"VEGFA\",\"LDHA\",\"PGK1\",\"ENO1\",\"SLC2A1\",\"PDK1\",\"NDRG1\",\"BNIP3\",\"CA9\"],\n",
    "    \"ER_Stress\": [\"XBP1\",\"ATF4\",\"ATF6\",\"DDIT3\",\"ERN1\",\"EIF2AK3\",\"HSPA5\",\"CALR\",\"CANX\"],\n",
    "    \"Oxidative_Stress\": [\"SOD1\",\"SOD2\",\"CAT\",\"GPX1\",\"PRDX1\",\"HMOX1\",\"NQO1\",\"TXNRD1\",\"GSR\",\"GCLC\"],\n",
    "}\n",
    "\n",
    "canonical_genes = find_genes_in_adata(CANONICAL_NERVE_MARKERS, adata.var)\n",
    "log(f\"Canonical markers found: {len(canonical_genes)}/{len(CANONICAL_NERVE_MARKERS)}\")\n",
    "if len(canonical_genes) == 0:\n",
    "    raise ValueError(\"No canonical nerve markers found. Check adata.var['gene_symbol'] and var_names mapping.\")\n",
    "\n",
    "stress_genes = {}\n",
    "for k, genes in GENERIC_STRESS_SETS.items():\n",
    "    stress_genes[k] = find_genes_in_adata(genes, adata.var)\n",
    "    log(f\"Stress {k}: found {len(stress_genes[k])}/{len(genes)}\")\n",
    "\n",
    "# Section 2: canonical nerve scoring + nerve-enriched definition\n",
    "X_log = adata.layers[\"log1p_norm\"]\n",
    "X_counts = adata.layers[\"counts\"]\n",
    "\n",
    "# canonical score = mean log1p_norm across available canonical genes\n",
    "canon_idx = [adata.var_names.get_loc(g) for g in canonical_genes]\n",
    "if sp.issparse(X_log):\n",
    "    canon_mat = X_log[:, canon_idx].toarray().astype(np.float32)\n",
    "else:\n",
    "    canon_mat = np.asarray(X_log[:, canon_idx], dtype=np.float32)\n",
    "\n",
    "adata.obs[\"canonical_nerve_score\"] = canon_mat.mean(axis=1)\n",
    "\n",
    "# marker hits = number of canonical genes detected (>0 counts) per spot\n",
    "if sp.issparse(X_counts):\n",
    "    hits = (X_counts[:, canon_idx] > 0).sum(axis=1)\n",
    "    hits = np.asarray(hits).ravel().astype(int)\n",
    "else:\n",
    "    hits = (X_counts[:, canon_idx] > 0).sum(axis=1).astype(int)\n",
    "\n",
    "adata.obs[\"canonical_marker_hits\"] = hits\n",
    "\n",
    "thr = np.percentile(adata.obs[\"canonical_nerve_score\"].values, 100.0 - PARAMS[\"nerve_region_top_percent\"])\n",
    "adata.obs[\"is_nerve_enriched\"] = ((adata.obs[\"canonical_nerve_score\"].values >= thr) &\n",
    "                                  (adata.obs[\"canonical_marker_hits\"].values >= PARAMS[\"min_markers_for_nerve\"])).astype(int)\n",
    "\n",
    "n_nerve = int(adata.obs[\"is_nerve_enriched\"].sum())\n",
    "log(f\"Nerve-enriched spots: {n_nerve:,}/{adata.n_obs:,} ({n_nerve/adata.n_obs*100:.2f}%)\")\n",
    "log(f\"Threshold canonical_nerve_score (top {PARAMS['nerve_region_top_percent']}%): {thr:.4f}\")\n",
    "log(f\"Min markers hit: {PARAMS['min_markers_for_nerve']}\")\n",
    "\n",
    "# Moran's I sanity (patched)\n",
    "I_canon = morans_I_sparse(adata.obs[\"canonical_nerve_score\"].values, W)\n",
    "log(f\"Canonical score Moran's I (W unstandardized): {I_canon:.4f}\")\n",
    "\n",
    "# Main Figure 2A\n",
    "log(\"Making Main Figure 2A...\")\n",
    "\n",
    "rep_sample = sorted(adata.obs[\"sample_id\"].unique())[0]\n",
    "rep = adata[adata.obs[\"sample_id\"] == rep_sample].copy()\n",
    "rep_mask_full = (adata.obs[\"sample_id\"].values == rep_sample)\n",
    "\n",
    "# choose up to 4 canonical genes to display\n",
    "show_genes = canonical_genes[:4]\n",
    "n_show = max(1, len(show_genes))\n",
    "\n",
    "fig = plt.figure(figsize=(7.2, 4.9), dpi=SAVE_DPI)\n",
    "gs = fig.add_gridspec(2, max(3, n_show), hspace=0.35, wspace=0.30)\n",
    "\n",
    "# top row: markers\n",
    "for i, gid in enumerate(show_genes):\n",
    "    ax = fig.add_subplot(gs[0, i])\n",
    "    j = adata.var_names.get_loc(gid)\n",
    "    if sp.issparse(X_log):\n",
    "        vals = X_log[rep_mask_full, j].toarray().ravel()\n",
    "    else:\n",
    "        vals = np.asarray(X_log[rep_mask_full, j]).ravel()\n",
    "    coords = rep.obsm[\"spatial\"]\n",
    "    sca = ax.scatter(coords[:,1], coords[:,0], c=vals, s=3, cmap=\"viridis\", alpha=0.95, rasterized=True)\n",
    "    ax.invert_yaxis()\n",
    "    title = adata.var.loc[gid, \"gene_symbol\"] if \"gene_symbol\" in adata.var.columns else gid\n",
    "    ax.set_title(title)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    cbar = plt.colorbar(sca, ax=ax, fraction=0.046, pad=0.04)\n",
    "    cbar.ax.tick_params(labelsize=5)\n",
    "\n",
    "# bottom-left: composite score\n",
    "ax_comp = fig.add_subplot(gs[1, :max(1, (max(3, n_show)//2))])\n",
    "coords = rep.obsm[\"spatial\"]\n",
    "comp = rep.obs[\"canonical_nerve_score\"].values\n",
    "sca = ax_comp.scatter(coords[:,1], coords[:,0], c=comp, s=3, cmap=\"Reds\", alpha=0.95, rasterized=True)\n",
    "ax_comp.invert_yaxis()\n",
    "ax_comp.set_title(\"Composite canonical score\")\n",
    "ax_comp.set_xticks([]); ax_comp.set_yticks([])\n",
    "cbar = plt.colorbar(sca, ax=ax_comp, fraction=0.046, pad=0.04)\n",
    "cbar.ax.tick_params(labelsize=5)\n",
    "\n",
    "# bottom-right: binary nerve mask\n",
    "ax_bin = fig.add_subplot(gs[1, max(1, (max(3, n_show)//2)) :])\n",
    "mask = rep.obs[\"is_nerve_enriched\"].values.astype(bool)\n",
    "ax_bin.scatter(coords[~mask,1], coords[~mask,0], s=2, c=\"lightgray\", alpha=0.5, rasterized=True, label=\"Rest\")\n",
    "ax_bin.scatter(coords[mask,1], coords[mask,0], s=4, c=\"red\", alpha=0.9, rasterized=True, label=\"Nerve-enriched\")\n",
    "ax_bin.invert_yaxis()\n",
    "ax_bin.set_title(f\"Nerve-enriched (n={mask.sum():,})\")\n",
    "ax_bin.set_xticks([]); ax_bin.set_yticks([])\n",
    "ax_bin.legend(loc=\"upper right\", frameon=False, fontsize=6, markerscale=2)\n",
    "\n",
    "fig.suptitle(\"Main Figure 2A: Canonical nerve markers\", y=0.98)\n",
    "fig2a_path = FIGURES_DIR / \"Main_Figure_2A.png\"\n",
    "fig.savefig(fig2a_path, dpi=SAVE_DPI, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "log(f\"Saved {fig2a_path}\")\n",
    "\n",
    "# Section 3: DE nerve vs rest\n",
    "\n",
    "log(\"Running DE: nerve vs rest (rank on log1p_norm; log2FC from normalized counts)...\")\n",
    "\n",
    "adata_de = adata.copy()\n",
    "adata_de.X = adata.layers[\"log1p_norm\"]  # ranking layer\n",
    "adata_de.obs[\"group\"] = np.where(adata_de.obs[\"is_nerve_enriched\"].values == 1, \"nerve\", \"rest\")\n",
    "\n",
    "sc.tl.rank_genes_groups(\n",
    "    adata_de,\n",
    "    groupby=\"group\",\n",
    "    groups=[\"nerve\"],\n",
    "    reference=\"rest\",\n",
    "    method=\"wilcoxon\",\n",
    "    use_raw=False,\n",
    "    pts=True,\n",
    "    tie_correct=True,\n",
    ")\n",
    "\n",
    "de = sc.get.rank_genes_groups_df(adata_de, group=\"nerve\").rename(columns={\"names\":\"gene\"})\n",
    "log(f\"DE table rows: {de.shape[0]:,}\")\n",
    "\n",
    "# map symbol\n",
    "if \"gene_symbol\" in adata.var.columns:\n",
    "    gene_map = adata.var[\"gene_symbol\"].to_dict()\n",
    "    de[\"gene_symbol\"] = de[\"gene\"].map(gene_map)\n",
    "else:\n",
    "    de[\"gene_symbol\"] = de[\"gene\"]\n",
    "\n",
    "# log2FC from counts normalized to 1e4 per spot (library size)\n",
    "nerve_mask = (adata.obs[\"is_nerve_enriched\"].values == 1)\n",
    "rest_mask = ~nerve_mask\n",
    "\n",
    "Xn = adata.layers[\"counts\"]\n",
    "lib = safe_sum(Xn, axis=1)\n",
    "lib[lib == 0] = 1.0\n",
    "if sp.issparse(Xn):\n",
    "    Xn_norm = Xn.multiply(1e4 / lib[:, None]).tocsr()\n",
    "else:\n",
    "    Xn_norm = (Xn / lib[:, None]) * 1e4\n",
    "\n",
    "mn = safe_mean(Xn_norm[nerve_mask], axis=0)\n",
    "mr = safe_mean(Xn_norm[rest_mask], axis=0)\n",
    "log2fc = np.log2((mn + 1e-9) / (mr + 1e-9))\n",
    "\n",
    "de[\"log2FC\"] = log2fc\n",
    "de[\"mean_nerve\"] = mn\n",
    "de[\"mean_rest\"] = mr\n",
    "de[\"pval\"] = de[\"pvals\"]\n",
    "de[\"pval_adj\"] = de[\"pvals_adj\"]\n",
    "\n",
    "sig_mask = (de[\"pval_adj\"] < PARAMS[\"de_padj_threshold\"]) & (np.abs(de[\"log2FC\"]) > PARAMS[\"de_log2fc_threshold\"])\n",
    "de_sig = de.loc[sig_mask].copy()\n",
    "\n",
    "log(f\"Significant DE: {de_sig.shape[0]:,} (padj<{PARAMS['de_padj_threshold']}, |log2FC|>{PARAMS['de_log2fc_threshold']})\")\n",
    "\n",
    "# Supplementary Table 4\n",
    "supp4_path = TABLES_DIR / \"Supplementary_Table_4.xlsx\"\n",
    "with pd.ExcelWriter(supp4_path, engine=\"openpyxl\") as w:\n",
    "    de.sort_values(\"scores\", ascending=False).to_excel(w, index=False, sheet_name=\"DE_Nerve_vs_Rest\")\n",
    "log(f\"Saved {supp4_path}\")\n",
    "\n",
    "# Main Figure 2B Volcano\n",
    "log(\"Making Main Figure 2B...\")\n",
    "fig, ax = plt.subplots(1, 1, figsize=(3.6, 3.6), dpi=SAVE_DPI)\n",
    "\n",
    "y = -np.log10(de[\"pval_adj\"].values + 1e-300)\n",
    "ax.scatter(de[\"log2FC\"].values, y, s=1, alpha=0.25, c=\"gray\", rasterized=True)\n",
    "\n",
    "ax.scatter(de.loc[sig_mask, \"log2FC\"].values,\n",
    "           -np.log10(de.loc[sig_mask, \"pval_adj\"].values + 1e-300),\n",
    "           s=2, alpha=0.7, c=\"red\", rasterized=True)\n",
    "\n",
    "ax.axhline(y=-np.log10(PARAMS[\"de_padj_threshold\"]), linestyle=\"--\", linewidth=0.8, alpha=0.6)\n",
    "ax.axvline(x=PARAMS[\"de_log2fc_threshold\"], linestyle=\"--\", linewidth=0.8, alpha=0.6)\n",
    "ax.axvline(x=-PARAMS[\"de_log2fc_threshold\"], linestyle=\"--\", linewidth=0.8, alpha=0.6)\n",
    "\n",
    "# annotate a few top by score\n",
    "top = de.sort_values(\"scores\", ascending=False).head(8)\n",
    "for _, r in top.iterrows():\n",
    "    ax.text(r[\"log2FC\"], -np.log10(r[\"pval_adj\"] + 1e-300), str(r[\"gene_symbol\"])[:12], fontsize=5, alpha=0.85)\n",
    "\n",
    "ax.set_xlabel(\"log2 fold-change\")\n",
    "ax.set_ylabel(\"-log10 adj. p-value\")\n",
    "ax.set_title(\"Main Figure 2B: DE volcano (nerve vs rest)\")\n",
    "fig2b_path = FIGURES_DIR / \"Main_Figure_2B.png\"\n",
    "fig.savefig(fig2b_path, dpi=SAVE_DPI, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "log(f\"Saved {fig2b_path}\")\n",
    "\n",
    "# Section 4: Pathway enrichment (optional, always produce Supp Fig 3 + Supp Table 5)\n",
    "supp5_path = TABLES_DIR / \"Supplementary_Table_5.xlsx\"\n",
    "supp_fig3_path = FIGURES_DIR / \"Supplementary_Figure_3.png\"\n",
    "\n",
    "if HAS_GSEAPY and de_sig.shape[0] >= 10:\n",
    "    log(\"Pathway enrichment (gseapy)...\")\n",
    "    # use upregulated symbols if available\n",
    "    up = de_sig.loc[de_sig[\"log2FC\"] > 0, \"gene_symbol\"].dropna().astype(str).unique().tolist()\n",
    "    up = [g for g in up if g and g.upper() != \"NAN\"]\n",
    "    if len(up) >= 10:\n",
    "        try:\n",
    "            enr = gp.enrichr(\n",
    "                gene_list=up,\n",
    "                gene_sets=[\"GO_Biological_Process_2021\", \"KEGG_2021_Human\"],\n",
    "                organism=\"Human\",\n",
    "                outdir=None\n",
    "            )\n",
    "            enr_df = enr.results.copy()\n",
    "            enr_sig = enr_df[enr_df[\"Adjusted P-value\"] < 0.05].copy()\n",
    "            with pd.ExcelWriter(supp5_path, engine=\"openpyxl\") as w:\n",
    "                enr_sig.to_excel(w, index=False, sheet_name=\"Enrichment\")\n",
    "            log(f\"Saved {supp5_path}\")\n",
    "\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(5.2, 3.8), dpi=SAVE_DPI)\n",
    "            if enr_sig.shape[0] > 0:\n",
    "                top_terms = enr_sig.nsmallest(20, \"Adjusted P-value\").copy()\n",
    "                ax.barh(range(len(top_terms)), -np.log10(top_terms[\"Adjusted P-value\"].values + 1e-300))\n",
    "                ax.set_yticks(range(len(top_terms)))\n",
    "                ax.set_yticklabels(top_terms[\"Term\"].values, fontsize=6)\n",
    "                ax.invert_yaxis()\n",
    "                ax.set_xlabel(\"-log10 adj. p-value\")\n",
    "                ax.set_title(\"Supplementary Figure 3: Enriched pathways (up genes)\")\n",
    "            else:\n",
    "                ax.text(0.02, 0.5, \"No enriched terms at FDR<0.05\", fontsize=7, transform=ax.transAxes)\n",
    "                ax.set_axis_off()\n",
    "\n",
    "            fig.savefig(supp_fig3_path, dpi=SAVE_DPI, bbox_inches=\"tight\")\n",
    "            plt.close(fig)\n",
    "            log(f\"Saved {supp_fig3_path}\")\n",
    "        except Exception as e:\n",
    "            log(f\"Enrichment failed: {type(e).__name__}: {e}\")\n",
    "            # write placeholder\n",
    "            with pd.ExcelWriter(supp5_path, engine=\"openpyxl\") as w:\n",
    "                pd.DataFrame({\"note\":[f\"Enrichment failed: {type(e).__name__}: {e}\"]}).to_excel(w, index=False, sheet_name=\"Enrichment\")\n",
    "            fig, ax = plt.subplots(1, 1, figsize=(5.2, 3.2), dpi=SAVE_DPI)\n",
    "            ax.text(0.02, 0.5, \"Enrichment failed (see Supplementary Table 5).\", fontsize=7, transform=ax.transAxes)\n",
    "            ax.set_axis_off()\n",
    "            fig.savefig(supp_fig3_path, dpi=SAVE_DPI, bbox_inches=\"tight\")\n",
    "            plt.close(fig)\n",
    "            log(f\"Saved {supp5_path}\")\n",
    "            log(f\"Saved {supp_fig3_path}\")\n",
    "    else:\n",
    "        log(\"Skipping enrichment: too few upregulated genes after filtering.\")\n",
    "        with pd.ExcelWriter(supp5_path, engine=\"openpyxl\") as w:\n",
    "            pd.DataFrame({\"note\":[\"Skipped: too few upregulated genes for enrichment.\"]}).to_excel(w, index=False, sheet_name=\"Enrichment\")\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(5.2, 3.2), dpi=SAVE_DPI)\n",
    "        ax.text(0.02, 0.5, \"Enrichment skipped (too few genes).\", fontsize=7, transform=ax.transAxes)\n",
    "        ax.set_axis_off()\n",
    "        fig.savefig(supp_fig3_path, dpi=SAVE_DPI, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "        log(f\"Saved {supp5_path}\")\n",
    "        log(f\"Saved {supp_fig3_path}\")\n",
    "else:\n",
    "    log(\"Skipping enrichment (gseapy unavailable or insufficient DE genes).\")\n",
    "    with pd.ExcelWriter(supp5_path, engine=\"openpyxl\") as w:\n",
    "        pd.DataFrame({\"note\":[f\"Skipped: gseapy={HAS_GSEAPY}, de_sig={de_sig.shape[0]}\"]}).to_excel(w, index=False, sheet_name=\"Enrichment\")\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(5.2, 3.2), dpi=SAVE_DPI)\n",
    "    ax.text(0.02, 0.5, \"Enrichment skipped.\", fontsize=7, transform=ax.transAxes)\n",
    "    ax.set_axis_off()\n",
    "    fig.savefig(supp_fig3_path, dpi=SAVE_DPI, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    log(f\"Saved {supp5_path}\")\n",
    "    log(f\"Saved {supp_fig3_path}\")\n",
    "\n",
    "# Section 5: Signature construction + benchmarking sizes/methods\n",
    "log(\"Building candidate signature list...\")\n",
    "\n",
    "# rank metric: scanpy score * |log2FC|\n",
    "de_sig[\"rank_metric\"] = de_sig[\"scores\"].values * np.abs(de_sig[\"log2FC\"].values)\n",
    "de_sig = de_sig.sort_values(\"rank_metric\", ascending=False)\n",
    "\n",
    "# optional Moran filter (only if present and not too destructive)\n",
    "use_moran = (\"morans_i\" in adata.var.columns)\n",
    "if use_moran:\n",
    "    m = adata.var[\"morans_i\"]\n",
    "    mor_map = m.to_dict()\n",
    "    de_sig[\"morans_i\"] = de_sig[\"gene\"].map(mor_map)\n",
    "    before = de_sig.shape[0]\n",
    "    de_sig_m = de_sig[np.isfinite(de_sig[\"morans_i\"].values) & (de_sig[\"morans_i\"].values > 0)].copy()\n",
    "    if de_sig_m.shape[0] >= min(PARAMS[\"signature_sizes\"]):\n",
    "        de_sig = de_sig_m\n",
    "        log(f\"Moran filter: {before}->{de_sig.shape[0]} genes with morans_i>0\")\n",
    "    else:\n",
    "        log(f\"Moran filter would be too aggressive ({before}->{de_sig_m.shape[0]}). Skipping Moran filter.\")\n",
    "\n",
    "# benchmark only mean_z and weighted (fast + stable)\n",
    "log(\"Benchmarking signature sizes / scoring methods...\")\n",
    "\n",
    "bench_rows = []\n",
    "y_true = adata.obs[\"is_nerve_enriched\"].values.astype(int)\n",
    "\n",
    "for n_genes in PARAMS[\"signature_sizes\"]:\n",
    "    cand = de_sig.head(n_genes)\n",
    "    genes_n = cand[\"gene\"].tolist()\n",
    "    weights_n = cand.set_index(\"gene\")[\"log2FC\"].to_dict()\n",
    "\n",
    "    s_mean = score_mean_z(adata, genes_n, layer=\"log1p_norm\")\n",
    "    s_w = score_weighted_mean(adata, genes_n, weights_n, layer=\"log1p_norm\")\n",
    "\n",
    "    auc_mean = roc_auc_score(y_true, s_mean) if len(np.unique(y_true)) == 2 else np.nan\n",
    "    auc_w = roc_auc_score(y_true, s_w) if len(np.unique(y_true)) == 2 else np.nan\n",
    "\n",
    "    bench_rows.append({\"n_genes\": n_genes, \"method\": \"mean_z\", \"auc\": float(auc_mean)})\n",
    "    bench_rows.append({\"n_genes\": n_genes, \"method\": \"weighted\", \"auc\": float(auc_w)})\n",
    "\n",
    "    log(f\"  n={n_genes}: mean_z AUC={auc_mean:.3f} | weighted AUC={auc_w:.3f}\")\n",
    "\n",
    "bench_df = pd.DataFrame(bench_rows)\n",
    "best = bench_df.loc[bench_df[\"auc\"].idxmax()]\n",
    "FINAL_N = int(best[\"n_genes\"])\n",
    "FINAL_METHOD = str(best[\"method\"])\n",
    "log(f\"Selected: n={FINAL_N}, method={FINAL_METHOD}, AUC={best['auc']:.3f}\")\n",
    "\n",
    "final_cand = de_sig.head(FINAL_N).copy()\n",
    "final_genes = final_cand[\"gene\"].tolist()\n",
    "final_weights = final_cand.set_index(\"gene\")[\"log2FC\"].to_dict()\n",
    "\n",
    "if FINAL_METHOD == \"mean_z\":\n",
    "    adata.obs[\"nerve_injury_score\"] = score_mean_z(adata, final_genes, layer=\"log1p_norm\")\n",
    "else:\n",
    "    adata.obs[\"nerve_injury_score\"] = score_weighted_mean(adata, final_genes, final_weights, layer=\"log1p_norm\")\n",
    "\n",
    "# separation\n",
    "s1 = adata.obs.loc[adata.obs[\"is_nerve_enriched\"] == 1, \"nerve_injury_score\"].values\n",
    "s0 = adata.obs.loc[adata.obs[\"is_nerve_enriched\"] == 0, \"nerve_injury_score\"].values\n",
    "u, p = mannwhitneyu(s1, s0, alternative=\"greater\")\n",
    "log(f\"Score separation (Mann-Whitney): p={p:.2e} | nerve mean={s1.mean():.3f} rest mean={s0.mean():.3f}\")\n",
    "\n",
    "# Export Supplementary Table 7 (benchmarking)\n",
    "supp7_path = TABLES_DIR / \"Supplementary_Table_7.xlsx\"\n",
    "with pd.ExcelWriter(supp7_path, engine=\"openpyxl\") as w:\n",
    "    bench_df.sort_values([\"auc\",\"n_genes\"], ascending=[False, True]).to_excel(w, index=False, sheet_name=\"SigSize_Benchmark\")\n",
    "log(f\"Saved {supp7_path}\")\n",
    "\n",
    "# Export signature v1.0\n",
    "sig = final_cand.copy()\n",
    "sig[\"signature_version\"] = VERSION\n",
    "sig[\"derivation_date\"] = RUN_TS\n",
    "sig[\"scoring_method\"] = FINAL_METHOD\n",
    "sig_path = PROCESSED_DIR / f\"nerve_injury_signature_{VERSION}.csv\"\n",
    "sig.to_csv(sig_path, index=False)\n",
    "log(f\"Saved signature: {sig_path}\")\n",
    "\n",
    "# Export per-spot scores\n",
    "scores_df = adata.obs[[\"sample_id\",\"canonical_nerve_score\",\"canonical_marker_hits\",\"is_nerve_enriched\",\"nerve_injury_score\"]].copy()\n",
    "scores_path = PROCESSED_DIR / \"nerve_injury_scores_per_spot.csv\"\n",
    "scores_df.to_csv(scores_path, index=True)\n",
    "log(f\"Saved scores: {scores_path}\")\n",
    "\n",
    "# Main Figure 2D (spatial validation + permutation histogram)\n",
    "I_sig = morans_I_sparse(adata.obs[\"nerve_injury_score\"].values, W)\n",
    "log(f\"Signature score Moran's I (W unstandardized): {I_sig:.4f}\")\n",
    "\n",
    "log(f\"Permutation tests: n={PARAMS['n_permutations']} (shuffle score on fixed graph)...\")\n",
    "perm = []\n",
    "sv = adata.obs[\"nerve_injury_score\"].values.astype(np.float32)\n",
    "for i in range(PARAMS[\"n_permutations\"]):\n",
    "    perm_idx = np.random.permutation(sv.shape[0])\n",
    "    perm.append(morans_I_sparse(sv[perm_idx], W))\n",
    "    if (i + 1) % PARAMS[\"perm_log_every\"] == 0:\n",
    "        log(f\"  perm {i+1}/{PARAMS['n_permutations']}\")\n",
    "\n",
    "perm = np.array([x for x in perm if np.isfinite(x)], dtype=np.float32)\n",
    "perm_p = float((np.sum(np.abs(perm) >= np.abs(I_sig)) + 1) / (len(perm) + 1))\n",
    "log(f\"Permutation p-value: {perm_p:.4f}\")\n",
    "\n",
    "# figure\n",
    "fig, axes = plt.subplots(1, 2, figsize=(7.0, 3.2), dpi=SAVE_DPI)\n",
    "\n",
    "# spatial map (rep sample)\n",
    "rep_mask_full = (adata.obs[\"sample_id\"].values == rep_sample)\n",
    "coords = adata[rep_mask_full].obsm[\"spatial\"]\n",
    "rep_scores = adata.obs.loc[rep_mask_full, \"nerve_injury_score\"].values\n",
    "scat = axes[0].scatter(coords[:,1], coords[:,0], c=rep_scores, s=3, cmap=\"coolwarm\", alpha=0.95, rasterized=True)\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].set_title(f\"A  Nerve injury score\\n{rep_sample}\")\n",
    "axes[0].set_xticks([]); axes[0].set_yticks([])\n",
    "cbar = plt.colorbar(scat, ax=axes[0], fraction=0.046, pad=0.04)\n",
    "cbar.ax.tick_params(labelsize=6)\n",
    "cbar.set_label(\"Score\")\n",
    "\n",
    "# permutation hist\n",
    "axes[1].hist(perm, bins=50, alpha=0.75, edgecolor=\"black\", linewidth=0.4)\n",
    "axes[1].axvline(x=I_sig, linestyle=\"--\", linewidth=1.0, color=\"red\", label=f\"Real I={I_sig:.3f}\")\n",
    "axes[1].set_title(f\"B  Permutation test\\np={perm_p:.4f}\")\n",
    "axes[1].set_xlabel(\"Moran's I\")\n",
    "axes[1].set_ylabel(\"Frequency\")\n",
    "axes[1].legend(frameon=False, fontsize=6)\n",
    "\n",
    "fig.suptitle(\"Main Figure 2D: Spatial validation\", y=0.98)\n",
    "fig2d_path = FIGURES_DIR / \"Main_Figure_2D.png\"\n",
    "fig.savefig(fig2d_path, dpi=SAVE_DPI, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "log(f\"Saved {fig2d_path}\")\n",
    "\n",
    "# Section 6: Bootstrap stability (PATCHED: CSR conversion)\n",
    "log(f\"Bootstrap stability: n_boot={PARAMS['n_bootstrap']}...\")\n",
    "\n",
    "boot_presence = {g: 0 for g in final_genes}\n",
    "boot_kept = 0\n",
    "\n",
    "counts = adata.layers[\"counts\"]\n",
    "\n",
    "for b in range(PARAMS[\"n_bootstrap\"]):\n",
    "    idx = np.random.choice(adata.n_obs, adata.n_obs, replace=True)\n",
    "\n",
    "    score_b = adata.obs[\"canonical_nerve_score\"].values[idx]\n",
    "    thr_b = np.percentile(score_b, 100.0 - PARAMS[\"nerve_region_top_percent\"])\n",
    "    hits_b = adata.obs[\"canonical_marker_hits\"].values[idx]\n",
    "    yb = (score_b >= thr_b) & (hits_b >= PARAMS[\"min_markers_for_nerve\"])\n",
    "\n",
    "    if yb.sum() < 50 or (~yb).sum() < 50:\n",
    "        continue\n",
    "\n",
    "    Xb = counts[idx]\n",
    "    libb = np.asarray(Xb.sum(axis=1)).ravel()\n",
    "    libb[libb == 0] = 1.0\n",
    "\n",
    "    if sp.issparse(Xb):\n",
    "        Xb_norm = Xb.multiply(1e4 / libb[:, None]).tocsr()  # <- critical\n",
    "    else:\n",
    "        Xb_norm = (Xb / libb[:, None]) * 1e4\n",
    "\n",
    "    mn_b = safe_mean(Xb_norm[yb], axis=0)\n",
    "    mr_b = safe_mean(Xb_norm[~yb], axis=0)\n",
    "    l2 = np.log2((mn_b + 1e-9) / (mr_b + 1e-9))\n",
    "\n",
    "    top_idx = np.argsort(l2)[::-1][:FINAL_N]\n",
    "    top_genes = set(adata.var_names[top_idx].tolist())\n",
    "    boot_kept += 1\n",
    "\n",
    "    for g in final_genes:\n",
    "        if g in top_genes:\n",
    "            boot_presence[g] += 1\n",
    "\n",
    "    if (b + 1) % 20 == 0:\n",
    "        log(f\"  boot {b+1}/{PARAMS['n_bootstrap']} (kept={boot_kept})\")\n",
    "\n",
    "boot_df = pd.DataFrame({\n",
    "    \"gene\": final_genes,\n",
    "    \"bootstrap_count\": [boot_presence[g] for g in final_genes],\n",
    "})\n",
    "boot_df[\"bootstrap_frequency_pct\"] = 100.0 * boot_df[\"bootstrap_count\"] / max(1, boot_kept)\n",
    "boot_df = boot_df.sort_values(\"bootstrap_frequency_pct\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "core_genes = boot_df.loc[boot_df[\"bootstrap_frequency_pct\"] >= 80.0, \"gene\"].tolist()\n",
    "log(f\"Bootstrap kept: {boot_kept}/{PARAMS['n_bootstrap']}\")\n",
    "log(f\"Core genes (>=80%): {len(core_genes)}\")\n",
    "\n",
    "# Supplementary Table 6\n",
    "supp6_path = TABLES_DIR / \"Supplementary_Table_6.xlsx\"\n",
    "with pd.ExcelWriter(supp6_path, engine=\"openpyxl\") as w:\n",
    "    boot_df.to_excel(w, index=False, sheet_name=\"Bootstrap\")\n",
    "log(f\"Saved {supp6_path}\")\n",
    "\n",
    "# Supplementary Figure 4\n",
    "fig, axes = plt.subplots(1, 2, figsize=(7.0, 3.0), dpi=SAVE_DPI)\n",
    "\n",
    "axes[0].hist(boot_df[\"bootstrap_frequency_pct\"].values, bins=15, edgecolor=\"black\", linewidth=0.4)\n",
    "axes[0].axvline(x=80, linestyle=\"--\", linewidth=0.9, color=\"red\")\n",
    "axes[0].set_title(\"A  Bootstrap frequency\")\n",
    "axes[0].set_xlabel(\"Frequency (%)\")\n",
    "axes[0].set_ylabel(\"Genes\")\n",
    "\n",
    "top30 = boot_df.head(30).copy()\n",
    "axes[1].barh(range(len(top30)), top30[\"bootstrap_frequency_pct\"].values)\n",
    "axes[1].set_yticks(range(len(top30)))\n",
    "axes[1].set_yticklabels(top30[\"gene\"].values, fontsize=6)\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].set_title(\"B  Top genes\")\n",
    "axes[1].set_xlabel(\"Frequency (%)\")\n",
    "\n",
    "fig.suptitle(\"Supplementary Figure 4: Bootstrap stability\", y=0.98)\n",
    "supp_fig4_path = FIGURES_DIR / \"Supplementary_Figure_4.png\"\n",
    "fig.savefig(supp_fig4_path, dpi=SAVE_DPI, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "log(f\"Saved {supp_fig4_path}\")\n",
    "\n",
    "# Section 8: Benchmark vs alternatives + Main Figure 2E\n",
    "alternatives = {}\n",
    "\n",
    "# naive: canonical mean_z (all canonical genes available)\n",
    "alternatives[\"Naive_canonical_meanZ\"] = score_mean_z(adata, canonical_genes, layer=\"log1p_norm\")\n",
    "\n",
    "# stress sets\n",
    "for name, genes in stress_genes.items():\n",
    "    if len(genes) >= 5:\n",
    "        alternatives[f\"Stress_{name}_meanZ\"] = score_mean_z(adata, genes, layer=\"log1p_norm\")\n",
    "\n",
    "# kitchen sink (top 500 by Wilcoxon score)\n",
    "kitchen = de.sort_values(\"scores\", ascending=False).head(500)[\"gene\"].tolist()\n",
    "alternatives[\"KitchenSink_top500_meanZ\"] = score_mean_z(adata, kitchen, layer=\"log1p_norm\")\n",
    "\n",
    "# our final\n",
    "alternatives[f\"OurSignature_{FINAL_N}_{FINAL_METHOD}\"] = adata.obs[\"nerve_injury_score\"].values.astype(np.float32)\n",
    "\n",
    "bench2_rows = []\n",
    "for name, s in alternatives.items():\n",
    "    fpr, tpr, _ = roc_curve(y_true, s)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    prec, rec, _ = precision_recall_curve(y_true, s)\n",
    "    pr_auc = auc(rec, prec)\n",
    "    thr90 = np.percentile(s, 90)  # top 10%\n",
    "    yhat = (s >= thr90).astype(int)\n",
    "    f1 = f1_score(y_true, yhat)\n",
    "\n",
    "    # Cohen's d\n",
    "    s_pos = s[y_true == 1]\n",
    "    s_neg = s[y_true == 0]\n",
    "    denom = np.sqrt(((s_pos.size - 1) * np.var(s_pos, ddof=1) + (s_neg.size - 1) * np.var(s_neg, ddof=1)) / (s_pos.size + s_neg.size - 2) + 1e-12)\n",
    "    d = float((np.mean(s_pos) - np.mean(s_neg)) / denom)\n",
    "\n",
    "    bench2_rows.append({\n",
    "        \"method\": name,\n",
    "        \"auc_roc\": float(roc_auc),\n",
    "        \"auc_pr\": float(pr_auc),\n",
    "        \"f1_top10pct\": float(f1),\n",
    "        \"cohens_d\": float(d),\n",
    "    })\n",
    "    log(f\"  {name}: AUC={roc_auc:.3f} | F1={f1:.3f} | d={d:.3f}\")\n",
    "\n",
    "bench2 = pd.DataFrame(bench2_rows).sort_values(\"auc_roc\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Main Figure 2E\n",
    "log(\"Making Main Figure 2E...\")\n",
    "fig, axes = plt.subplots(1, 2, figsize=(7.2, 3.3), dpi=SAVE_DPI)\n",
    "\n",
    "# ROC curves\n",
    "for name, s in alternatives.items():\n",
    "    fpr, tpr, _ = roc_curve(y_true, s)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    if name.startswith(\"OurSignature\"):\n",
    "        axes[0].plot(fpr, tpr, linewidth=1.5, color=\"red\", label=f\"{name} (AUC={roc_auc:.3f})\")\n",
    "    else:\n",
    "        axes[0].plot(fpr, tpr, linewidth=0.9, alpha=0.75, label=f\"{name} (AUC={roc_auc:.3f})\")\n",
    "axes[0].plot([0,1],[0,1], \"k--\", linewidth=0.8, alpha=0.5)\n",
    "axes[0].set_xlabel(\"False positive rate\")\n",
    "axes[0].set_ylabel(\"True positive rate\")\n",
    "axes[0].set_title(\"A  ROC\")\n",
    "axes[0].legend(frameon=False, fontsize=5, loc=\"lower right\")\n",
    "\n",
    "# bar AUC\n",
    "axes[1].barh(range(bench2.shape[0]), bench2[\"auc_roc\"].values)\n",
    "axes[1].set_yticks(range(bench2.shape[0]))\n",
    "axes[1].set_yticklabels(bench2[\"method\"].values, fontsize=6)\n",
    "axes[1].invert_yaxis()\n",
    "axes[1].set_xlabel(\"AUC (ROC)\")\n",
    "axes[1].set_title(\"B  Comparison\")\n",
    "\n",
    "# highlight our bar\n",
    "for i, m in enumerate(bench2[\"method\"].values):\n",
    "    if m.startswith(\"OurSignature\"):\n",
    "        axes[1].patches[i].set_color(\"red\")\n",
    "\n",
    "fig.suptitle(\"Main Figure 2E: Benchmarking\", y=0.98)\n",
    "fig2e_path = FIGURES_DIR / \"Main_Figure_2E.png\"\n",
    "fig.savefig(fig2e_path, dpi=SAVE_DPI, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "log(f\"Saved {fig2e_path}\")\n",
    "\n",
    "# Supplementary Table 7 already used for sig-size benchmarking.\n",
    "# Export method benchmarking as Supplementary Table 7B (same file, second sheet) to avoid extra tables.\n",
    "with pd.ExcelWriter(supp7_path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as w:\n",
    "    bench2.to_excel(w, index=False, sheet_name=\"Method_Benchmark\")\n",
    "log(f\"Updated {supp7_path} with Method_Benchmark sheet\")\n",
    "\n",
    "# Section 9: Published CINI comparison + Supplementary Figure 5\n",
    "PUBLISHED_CINI = [\n",
    "    \"TAGAP\",\"KCNJ8\",\"COL1A1\",\"PECAM1\",\"TMEM119\",\"ATF3\",\"JUN\",\"KLF6\",\"NOCT\",\"LMO7\",\n",
    "    \"CSF1\",\"ENTPD1\",\"UCHL1\",\"PINK1\",\"BHLHE41\",\"ITGAM\",\"CHL1\",\"SNCA\",\"SCPEP1\",\"VEGFA\"\n",
    "]\n",
    "pub_genes = find_genes_in_adata(PUBLISHED_CINI, adata.var)\n",
    "log(f\"Published CINI genes found: {len(pub_genes)}/{len(PUBLISHED_CINI)}\")\n",
    "\n",
    "supp_fig5_path = FIGURES_DIR / \"Supplementary_Figure_5.png\"\n",
    "\n",
    "if len(pub_genes) >= 5:\n",
    "    pub_score = score_mean_z(adata, pub_genes, layer=\"log1p_norm\")\n",
    "    our_score = adata.obs[\"nerve_injury_score\"].values.astype(np.float32)\n",
    "\n",
    "    fpr_p, tpr_p, _ = roc_curve(y_true, pub_score)\n",
    "    fpr_o, tpr_o, _ = roc_curve(y_true, our_score)\n",
    "    auc_p = auc(fpr_p, tpr_p)\n",
    "    auc_o = auc(fpr_o, tpr_o)\n",
    "\n",
    "    # overlap in SYMBOL space\n",
    "    our_syms = set(adata.var.loc[final_genes, \"gene_symbol\"].astype(str).str.upper()) if \"gene_symbol\" in adata.var.columns else set([g.upper() for g in final_genes])\n",
    "    pub_syms = set([g.upper() for g in PUBLISHED_CINI])\n",
    "    ov = sorted(list(our_syms.intersection(pub_syms)))\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(7.0, 3.1), dpi=SAVE_DPI)\n",
    "\n",
    "    axes[0].plot(fpr_o, tpr_o, color=\"red\", linewidth=1.5, label=f\"Our (AUC={auc_o:.3f})\")\n",
    "    axes[0].plot(fpr_p, tpr_p, color=\"black\", linewidth=0.9, alpha=0.85, label=f\"Published CINI (AUC={auc_p:.3f})\")\n",
    "    axes[0].plot([0,1],[0,1], \"k--\", linewidth=0.8, alpha=0.5)\n",
    "    axes[0].set_title(\"A  ROC comparison\")\n",
    "    axes[0].set_xlabel(\"FPR\")\n",
    "    axes[0].set_ylabel(\"TPR\")\n",
    "    axes[0].legend(frameon=False, fontsize=6, loc=\"lower right\")\n",
    "\n",
    "    axes[1].axis(\"off\")\n",
    "    txt = \"Overlap (symbol):\\n\" + (\", \".join(ov) if len(ov) > 0 else \"None\")\n",
    "    txt += f\"\\n\\nn(Our)={len(our_syms)}\\nn(Published)={len(pub_syms)}\\n|Overlap|={len(ov)}\"\n",
    "    axes[1].text(0.02, 0.98, txt, va=\"top\", ha=\"left\", fontsize=7)\n",
    "\n",
    "    fig.suptitle(\"Supplementary Figure 5: Published signature comparison\", y=0.98)\n",
    "    fig.savefig(supp_fig5_path, dpi=SAVE_DPI, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    log(f\"Saved {supp_fig5_path}\")\n",
    "else:\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6.0, 2.5), dpi=SAVE_DPI)\n",
    "    ax.text(0.02, 0.6, \"Published CINI comparison skipped\\n(too few genes found in this AnnData).\", fontsize=7, transform=ax.transAxes)\n",
    "    ax.set_axis_off()\n",
    "    fig.savefig(supp_fig5_path, dpi=SAVE_DPI, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    log(f\"Saved {supp_fig5_path}\")\n",
    "\n",
    "# Final exports\n",
    "# Add bootstrap freq to signature and write FINAL\n",
    "boot_map = boot_df.set_index(\"gene\")[\"bootstrap_frequency_pct\"].to_dict()\n",
    "sig_final = sig.copy()\n",
    "sig_final[\"bootstrap_frequency_pct\"] = sig_final[\"gene\"].map(boot_map)\n",
    "sig_final_path = PROCESSED_DIR / f\"nerve_injury_signature_{VERSION}_FINAL.csv\"\n",
    "sig_final.to_csv(sig_final_path, index=False)\n",
    "log(f\"Saved FINAL signature: {sig_final_path}\")\n",
    "\n",
    "# Supplementary Table 6 already.\n",
    "# Save annotated AnnData\n",
    "adata_out = PROCESSED_DIR / \"adata_with_signature_scores.h5ad\"\n",
    "adata.write_h5ad(adata_out)\n",
    "log(f\"Saved annotated adata: {adata_out}\")\n",
    "\n",
    "# README\n",
    "readme_path = PROCESSED_DIR / \"README_signature.md\"\n",
    "readme_path.write_text(\n",
    "f\"\"\"# Nerve injury signature ({VERSION})\n",
    "\n",
    "Derived from GSE289745 Visium (cSCC) using canonical nerve marker enrichment to define nerve-enriched spots,\n",
    "DE ranking (Wilcoxon in log space), and candidate-gene selection with effect-size filtering.\n",
    "\n",
    "Key outputs:\n",
    "- {sig_final_path.name}\n",
    "- nerve_injury_scores_per_spot.csv\n",
    "- Main_Figure_2A/B/D/E.png\n",
    "- Supplementary_Table_4/5/6/7.xlsx\n",
    "- Supplementary_Figure_3/4/5.png\n",
    "\n",
    "Scoring:\n",
    "- FINAL_N={FINAL_N}\n",
    "- FINAL_METHOD={FINAL_METHOD}\n",
    "- Moran's I (signature)={I_sig:.4f} | perm p={perm_p:.4f}\n",
    "- Bootstrap kept={boot_kept}\n",
    "\n",
    "\"\"\",\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "log(f\"Saved README: {readme_path}\")\n",
    "\n",
    "log(\"Notebook 2 COMPLETE\")\n",
    "log(f\"FINAL_N={FINAL_N} | FINAL_METHOD={FINAL_METHOD} | AUC={best['auc']:.3f}\")\n",
    "log(f\"Signature Moran's I={I_sig:.4f} | perm p={perm_p:.4f}\")\n",
    "log(f\"Bootstrap kept={boot_kept} | core>=80%: {len(core_genes)}\")\n",
    "log(f\"End: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "\n",
    "print(\"\\nDone.\")\n",
    "print(\"Figures:\", FIGURES_DIR)\n",
    "print(\"Tables :\", TABLES_DIR)\n",
    "print(\"Processed:\", PROCESSED_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.5.1 (histopathology)",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}